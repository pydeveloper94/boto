




--- beanstalk/response.py	(original)
+++ beanstalk/response.py	(refactored)
@@ -7,7 +7,7 @@
     def __repr__(self):
         result = self.__class__.__name__ + '{ '
         counter = 0
-        for key, value in self.__dict__.iteritems():
+        for key, value in self.__dict__.items():
             # first iteration no comma
             counter += 1
             if counter > 1:
--- beanstalk/wrapper.py	(original)
+++ beanstalk/wrapper.py	(refactored)
@@ -9,7 +9,7 @@
     def _wrapped_low_level_api(*args, **kwargs):
         try:
             response = func(*args, **kwargs)
-        except BotoServerError, e:
+        except BotoServerError as e:
             raise exception.simple(e)
         # Turn 'this_is_a_function_name' into 'ThisIsAFunctionNameResponse'.
         cls_name = ''.join([part.capitalize() for part in name.split('_')]) + 'Response'
--- cloudformation/__init__.py	(original)
+++ cloudformation/__init__.py	(refactored)
@@ -20,7 +20,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-from connection import CloudFormationConnection
+from .connection import CloudFormationConnection
 from boto.regioninfo import RegionInfo, get_regions, load_regions
 
 RegionData = load_regions().get('cloudformation')
--- cloudfront/__init__.py	(original)
+++ cloudfront/__init__.py	(refactored)
@@ -54,7 +54,7 @@
 
     def get_etag(self, response):
         response_headers = response.msg
-        for key in response_headers.keys():
+        for key in list(response_headers.keys()):
             if key.lower() == 'etag':
                 return response_headers[key]
         return None
@@ -90,7 +90,7 @@
             raise CloudFrontServerError(response.status, response.reason, body)
         d = dist_class(connection=self)
         response_headers = response.msg
-        for key in response_headers.keys():
+        for key in list(response_headers.keys()):
             if key.lower() == 'etag':
                 d.etag = response_headers[key]
         h = handler.XmlHandler(d, self)
@@ -316,7 +316,7 @@
             params['MaxItems'] = max_items
         if params:
             uri += '?%s=%s' % params.popitem()
-            for k, v in params.items():
+            for k, v in list(params.items()):
                 uri += '&%s=%s' % (k, v)
         tags=[('InvalidationSummary', InvalidationSummary)]
         rs_class = InvalidationListResultSet
--- cloudfront/distribution.py	(original)
+++ cloudfront/distribution.py	(refactored)
@@ -665,7 +665,7 @@
             raise ValueError("You must specify one of private_key_file or private_key_string")
         # If private_key_file is a file name, open it and read it
         if private_key_string is None:
-            if isinstance(private_key_file, basestring):
+            if isinstance(private_key_file, str):
                 with open(private_key_file, 'r') as file_handle:
                     private_key_string = file_handle.read()
             # Otherwise, treat it like a file
--- cloudfront/invalidation.py	(original)
+++ cloudfront/invalidation.py	(refactored)
@@ -20,7 +20,7 @@
 # IN THE SOFTWARE.
 
 import uuid
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 from boto.resultset import ResultSet
 
@@ -71,7 +71,7 @@
         """Escape a path, make sure it begins with a slash and contains no invalid characters"""
         if not p[0] == "/":
             p = "/%s" % p
-        return urllib.quote(p)
+        return urllib.parse.quote(p)
 
     def to_xml(self):
         """Get this batch as XML"""
--- cloudfront/origin.py	(original)
+++ cloudfront/origin.py	(refactored)
@@ -20,7 +20,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-from identity import OriginAccessIdentity
+from .identity import OriginAccessIdentity
 
 def get_oai_value(origin_access_identity):
     if isinstance(origin_access_identity, OriginAccessIdentity):
--- cloudsearch/search.py	(original)
+++ cloudsearch/search.py	(refactored)
@@ -52,9 +52,9 @@
 
         self.facets = {}
         if 'facets' in attrs:
-            for (facet, values) in attrs['facets'].iteritems():
+            for (facet, values) in attrs['facets'].items():
                 if 'constraints' in values:
-                    self.facets[facet] = dict((k, v) for (k, v) in map(lambda x: (x['value'], x['count']), values['constraints']))
+                    self.facets[facet] = dict((k, v) for (k, v) in [(x['value'], x['count']) for x in values['constraints']])
 
         self.num_pages_needed = ceil(self.hits / self.query.real_size)
 
@@ -129,19 +129,19 @@
             params['facet'] = ','.join(self.facet)
 
         if self.facet_constraints:
-            for k, v in self.facet_constraints.iteritems():
+            for k, v in self.facet_constraints.items():
                 params['facet-%s-constraints' % k] = v
 
         if self.facet_sort:
-            for k, v in self.facet_sort.iteritems():
+            for k, v in self.facet_sort.items():
                 params['facet-%s-sort' % k] = v
 
         if self.facet_top_n:
-            for k, v in self.facet_top_n.iteritems():
+            for k, v in self.facet_top_n.items():
                 params['facet-%s-top-n' % k] = v
 
         if self.t:
-            for k, v in self.t.iteritems():
+            for k, v in self.t.items():
                 params['t-%s' % k] = v
         return params
 
@@ -290,7 +290,7 @@
         r = requests.get(url, params=params)
         try:
             data = json.loads(r.content)
-        except ValueError, e:
+        except ValueError as e:
             if r.status_code == 403:
                 msg = ''
                 import re
--- cloudsearch2/layer1.py	(original)
+++ cloudsearch2/layer1.py	(refactored)
@@ -759,9 +759,9 @@
         :type value: any
         :param value: The value to serialize
         """
-        for k, v in value.items():
+        for k, v in list(value.items()):
             if isinstance(v, dict):
-                for k2, v2 in v.items():
+                for k2, v2 in list(v.items()):
                     self.build_complex_param(params, label + '.' + k, v)
             elif isinstance(v, bool):
                 params['%s.%s' % (label, k)] = v and 'true' or 'false'
--- cloudsearch2/layer2.py	(original)
+++ cloudsearch2/layer2.py	(refactored)
@@ -33,7 +33,7 @@
                  host=None, debug=0, session_token=None, region=None,
                  validate_certs=True):
 
-        if type(region) in [str, unicode]:
+        if type(region) in [str, str]:
             import boto.cloudsearch2
             for region_info in boto.cloudsearch2.regions():
                 if region_info.name == region:
--- cloudsearch2/search.py	(original)
+++ cloudsearch2/search.py	(refactored)
@@ -52,9 +52,9 @@
 
         self.facets = {}
         if 'facets' in attrs:
-            for (facet, values) in attrs['facets'].iteritems():
+            for (facet, values) in attrs['facets'].items():
                 if 'buckets' in values:
-                    self.facets[facet] = dict((k, v) for (k, v) in map(lambda x: (x['value'], x['count']), values.get('buckets', [])))
+                    self.facets[facet] = dict((k, v) for (k, v) in [(x['value'], x['count']) for x in values.get('buckets', [])])
 
         self.num_pages_needed = ceil(self.hits / self.query.real_size)
 
@@ -123,17 +123,17 @@
             params['fq'] = self.fq
 
         if self.expr:
-            for k, v in self.expr.iteritems():
+            for k, v in self.expr.items():
                 params['expr.%s' % k] = v
 
         if self.facet:
-            for k, v in self.facet.iteritems():
-                if type(v) not in [str, unicode]:
+            for k, v in self.facet.items():
+                if type(v) not in [str, str]:
                     v = json.dumps(v)
                 params['facet.%s' % k] = v
 
         if self.highlight:
-            for k, v in self.highlight.iteritems():
+            for k, v in self.highlight.items():
                 params['highlight.%s' % k] = v
 
         if self.options:
@@ -283,7 +283,7 @@
         r = self.session.get(url, params=params)
         try:
             data = json.loads(r.content)
-        except ValueError, e:
+        except ValueError as e:
             if r.status_code == 403:
                 msg = ''
                 import re
--- connection.py	(original)
+++ connection.py	(refactored)
@@ -43,25 +43,25 @@
 Handles basic connections to AWS
 """
 
-from __future__ import with_statement
+
 import base64
 from datetime import datetime
 import errno
-import httplib
+import http.client
 import os
-import Queue
+import queue
 import random
 import re
 import socket
 import sys
 import time
-import urllib
-import urlparse
+import urllib.request, urllib.parse, urllib.error
+import urllib.parse
 import xml.sax
 import copy
 
-import auth
-import auth_handler
+from . import auth
+from . import auth_handler
 import boto
 import boto.utils
 import boto.handler
@@ -74,6 +74,7 @@
 from boto.exception import PleaseRetryException
 from boto.provider import Provider
 from boto.resultset import ResultSet
+import collections
 
 HAVE_HTTPS_CONNECTION = False
 try:
@@ -258,7 +259,7 @@
         """
         Returns the number of connections in the pool.
         """
-        return sum(pool.size() for pool in self.host_to_pool.values())
+        return sum(pool.size() for pool in list(self.host_to_pool.values()))
 
     def get_http_connection(self, host, port, is_secure):
         """
@@ -297,7 +298,7 @@
             now = time.time()
             if self.last_clean_time + self.CLEAN_INTERVAL < now:
                 to_remove = []
-                for (host, pool) in self.host_to_pool.items():
+                for (host, pool) in list(self.host_to_pool.items()):
                     pool.clean()
                     if pool.size() == 0:
                         to_remove.append(host)
@@ -372,9 +373,9 @@
     def authorize(self, connection, **kwargs):
         for key in self.headers:
             val = self.headers[key]
-            if isinstance(val, unicode):
+            if isinstance(val, str):
                 safe = '!"#$%&\'()*+,/:;<=>?@[\\]^`{|}~'
-                self.headers[key] = urllib.quote(val.encode('utf-8'), safe)
+                self.headers[key] = urllib.parse.quote(val.encode('utf-8'), safe)
 
         connection._auth_handler.add_auth(self, **kwargs)
 
@@ -387,10 +388,10 @@
                 self.headers['Content-Length'] = str(len(self.body))
 
 
-class HTTPResponse(httplib.HTTPResponse):
+class HTTPResponse(http.client.HTTPResponse):
 
     def __init__(self, *args, **kwargs):
-        httplib.HTTPResponse.__init__(self, *args, **kwargs)
+        http.client.HTTPResponse.__init__(self, *args, **kwargs)
         self._cached_response = ''
 
     def read(self, amt=None):
@@ -410,10 +411,10 @@
             # will return the full body.  Note that this behavior only
             # happens if the amt arg is not specified.
             if not self._cached_response:
-                self._cached_response = httplib.HTTPResponse.read(self)
+                self._cached_response = http.client.HTTPResponse.read(self)
             return self._cached_response
         else:
-            return httplib.HTTPResponse.read(self, amt)
+            return http.client.HTTPResponse.read(self, amt)
 
 
 class AWSAuthConnection(object):
@@ -506,8 +507,8 @@
 
         self.handle_proxy(proxy, proxy_port, proxy_user, proxy_pass)
         # define exceptions from httplib that we want to catch and retry
-        self.http_exceptions = (httplib.HTTPException, socket.error,
-                                socket.gaierror, httplib.BadStatusLine)
+        self.http_exceptions = (http.client.HTTPException, socket.error,
+                                socket.gaierror, http.client.BadStatusLine)
         # define subclasses of the above that are not retryable.
         self.http_unretryable_exceptions = []
         if HAVE_HTTPS_CONNECTION:
@@ -528,7 +529,7 @@
         self.host = host
         self.path = path
         # if the value passed in for debug
-        if not isinstance(debug, (int, long)):
+        if not isinstance(debug, int):
             debug = 0
         self.debug = config.getint('Boto', 'debug', debug)
         self.host_header = None
@@ -693,8 +694,8 @@
                 self.proxy_pass = config.get_value('Boto', 'proxy_pass', None)
 
         if not self.proxy_port and self.proxy:
-            print "http_proxy environment variable does not specify " \
-                "a port, using default"
+            print("http_proxy environment variable does not specify " \
+                "a port, using default")
             self.proxy_port = self.port
 
         self.no_proxy = os.environ.get('no_proxy', '') or os.environ.get('NO_PROXY', '')
@@ -755,7 +756,7 @@
                         host, ca_certs=self.ca_certificates_file,
                         **http_connection_kwargs)
             else:
-                connection = httplib.HTTPSConnection(host,
+                connection = http.client.HTTPSConnection(host,
                         **http_connection_kwargs)
         else:
             boto.log.debug('establishing HTTP connection: kwargs=%s' %
@@ -766,7 +767,7 @@
                 connection = self.https_connection_factory(host,
                     **http_connection_kwargs)
             else:
-                connection = httplib.HTTPConnection(host,
+                connection = http.client.HTTPConnection(host,
                     **http_connection_kwargs)
         if self.debug > 1:
             connection.set_debuglevel(self.debug)
@@ -799,7 +800,7 @@
         sock.sendall("CONNECT %s HTTP/1.0\r\n" % host)
         sock.sendall("User-Agent: %s\r\n" % UserAgent)
         if self.proxy_user and self.proxy_pass:
-            for k, v in self.get_proxy_auth_header().items():
+            for k, v in list(self.get_proxy_auth_header().items()):
                 sock.sendall("%s: %s\r\n" % (k, v))
             # See discussion about this config option at
             # https://groups.google.com/forum/?fromgroups#!topic/boto-dev/teenFvOq2Cc
@@ -807,7 +808,7 @@
                 sock.sendall("\r\n")
         else:
             sock.sendall("\r\n")
-        resp = httplib.HTTPResponse(sock, strict=True, debuglevel=self.debug)
+        resp = http.client.HTTPResponse(sock, strict=True, debuglevel=self.debug)
         resp.begin()
 
         if resp.status != 200:
@@ -821,7 +822,7 @@
         # We can safely close the response, it duped the original socket
         resp.close()
 
-        h = httplib.HTTPConnection(host)
+        h = http.client.HTTPConnection(host)
 
         if self.https_validate_certificates and HAVE_HTTPS_CONNECTION:
             msg = "wrapping ssl socket for proxied connection; "
@@ -844,10 +845,10 @@
         else:
             # Fallback for old Python without ssl.wrap_socket
             if hasattr(httplib, 'ssl'):
-                sslSock = httplib.ssl.SSLSocket(sock)
+                sslSock = http.client.ssl.SSLSocket(sock)
             else:
                 sslSock = socket.ssl(sock, None, None)
-                sslSock = httplib.FakeSocket(sock, sslSock)
+                sslSock = http.client.FakeSocket(sock, sslSock)
 
         # This is a bit unclean
         h.sock = sslSock
@@ -914,7 +915,7 @@
                     if not getattr(self, 'anon', False):
                         self.set_host_header(request)
                 request.start_time = datetime.now()
-                if callable(sender):
+                if isinstance(sender, collections.Callable):
                     response = sender(connection, request.method, request.path,
                                       request.body, request.headers)
                 else:
@@ -928,7 +929,7 @@
                 if request.method == 'HEAD' and getattr(response,
                                                         'chunked', False):
                     response.chunked = 0
-                if callable(retry_handler):
+                if isinstance(retry_handler, collections.Callable):
                     status = retry_handler(response, i, next_sleep)
                     if status:
                         msg, i, next_sleep = status
@@ -959,7 +960,7 @@
                     return response
                 else:
                     scheme, request.host, request.path, \
-                        params, query, fragment = urlparse.urlparse(location)
+                        params, query, fragment = urllib.parse.urlparse(location)
                     if query:
                         request.path += '?' + query
                     # urlparse can return both host and port in netloc, so if
@@ -974,12 +975,12 @@
                                                           scheme == 'https')
                     response = None
                     continue
-            except PleaseRetryException, e:
+            except PleaseRetryException as e:
                 boto.log.debug('encountered a retry exception: %s' % e)
                 connection = self.new_http_connection(request.host, request.port,
                                                       self.is_secure)
                 response = e.response
-            except self.http_exceptions, e:
+            except self.http_exceptions as e:
                 for unretryable in self.http_unretryable_exceptions:
                     if isinstance(e, unretryable):
                         boto.log.debug(
@@ -1089,7 +1090,7 @@
         return self._mexe(http_request)
 
     def build_list_params(self, params, items, label):
-        if isinstance(items, basestring):
+        if isinstance(items, str):
             items = [items]
         for i in range(1, len(items) + 1):
             params['%s.%d' % (label, i)] = items[i - 1]
--- dynamodb/batch.py	(original)
+++ dynamodb/batch.py	(refactored)
@@ -176,7 +176,7 @@
         if not self.unprocessed:
             return None
 
-        for table_name, table_req in self.unprocessed.iteritems():
+        for table_name, table_req in self.unprocessed.items():
             table_keys = table_req['Keys']
             table = self.layer2.get_table(table_name)
 
--- dynamodb/item.py	(original)
+++ dynamodb/item.py	(refactored)
@@ -51,7 +51,7 @@
                 range_key = attrs.get(self._range_key_name, None)
             self[self._range_key_name] = range_key
         self._updates = {}
-        for key, value in attrs.items():
+        for key, value in list(attrs.items()):
             if key != self._hash_key_name and key != self._range_key_name:
                 self[key] = value
         self.consumed_units = 0
--- dynamodb/layer2.py	(original)
+++ dynamodb/layer2.py	(refactored)
@@ -264,13 +264,13 @@
         """
         dynamodb_key = {}
         dynamodb_value = self.dynamizer.encode(hash_key)
-        if dynamodb_value.keys()[0] != schema.hash_key_type:
+        if list(dynamodb_value.keys())[0] != schema.hash_key_type:
             msg = 'Hashkey must be of type: %s' % schema.hash_key_type
             raise TypeError(msg)
         dynamodb_key['HashKeyElement'] = dynamodb_value
         if range_key is not None:
             dynamodb_value = self.dynamizer.encode(range_key)
-            if dynamodb_value.keys()[0] != schema.range_key_type:
+            if list(dynamodb_value.keys())[0] != schema.range_key_type:
                 msg = 'RangeKey must be of type: %s' % schema.range_key_type
                 raise TypeError(msg)
             dynamodb_key['RangeKeyElement'] = dynamodb_value
--- dynamodb/table.py	(original)
+++ dynamodb/table.py	(refactored)
@@ -47,16 +47,16 @@
         self.consistent_read = consistent_read
 
     def _queue_unprocessed(self, res):
-        if not u'UnprocessedKeys' in res:
+        if not 'UnprocessedKeys' in res:
             return
-        if not self.table.name in res[u'UnprocessedKeys']:
+        if not self.table.name in res['UnprocessedKeys']:
             return
 
-        keys = res[u'UnprocessedKeys'][self.table.name][u'Keys']
+        keys = res['UnprocessedKeys'][self.table.name]['Keys']
 
         for key in keys:
-            h = key[u'HashKeyElement']
-            r = key[u'RangeKeyElement'] if u'RangeKeyElement' in key else None
+            h = key['HashKeyElement']
+            r = key['RangeKeyElement'] if 'RangeKeyElement' in key else None
             self.keys.append((h, r))
 
     def __iter__(self):
@@ -68,10 +68,10 @@
             res = batch.submit()
 
             # parse the results
-            if not self.table.name in res[u'Responses']:
+            if not self.table.name in res['Responses']:
                 continue
-            self.consumed_units += res[u'Responses'][self.table.name][u'ConsumedCapacityUnits']
-            for elem in res[u'Responses'][self.table.name][u'Items']:
+            self.consumed_units += res['Responses'][self.table.name]['ConsumedCapacityUnits']
+            for elem in res['Responses'][self.table.name]['Items']:
                 yield elem
 
             # re-queue un processed keys
--- dynamodb/types.py	(original)
+++ dynamodb/types.py	(refactored)
@@ -27,7 +27,7 @@
 import base64
 from decimal import (Decimal, DecimalException, Context,
                      Clamped, Overflow, Inexact, Underflow, Rounded)
-from exceptions import DynamoDBNumberError
+from .exceptions import DynamoDBNumberError
 
 
 DYNAMODB_CONTEXT = Context(
@@ -51,13 +51,13 @@
 
 
 def is_num(n):
-    types = (int, long, float, bool, Decimal)
+    types = (int, int, float, bool, Decimal)
     return isinstance(n, types) or n in types
 
 
 def is_str(n):
-    return isinstance(n, basestring) or (isinstance(n, type) and
-                                         issubclass(n, basestring))
+    return isinstance(n, str) or (isinstance(n, type) and
+                                         issubclass(n, str))
 
 
 def is_binary(n):
@@ -97,11 +97,11 @@
     elif is_str(val):
         dynamodb_type = 'S'
     elif isinstance(val, (set, frozenset)):
-        if False not in map(is_num, val):
+        if False not in list(map(is_num, val)):
             dynamodb_type = 'NS'
-        elif False not in map(is_str, val):
+        elif False not in list(map(is_str, val)):
             dynamodb_type = 'SS'
-        elif False not in map(is_binary, val):
+        elif False not in list(map(is_binary, val)):
             dynamodb_type = 'BS'
     elif isinstance(val, Binary):
         dynamodb_type = 'B'
@@ -124,7 +124,7 @@
     elif dynamodb_type == 'S':
         val = {dynamodb_type: val}
     elif dynamodb_type == 'NS':
-        val = {dynamodb_type: map(serialize_num, val)}
+        val = {dynamodb_type: list(map(serialize_num, val))}
     elif dynamodb_type == 'SS':
         val = {dynamodb_type: [n for n in val]}
     elif dynamodb_type == 'B':
@@ -136,7 +136,7 @@
 
 class Binary(object):
     def __init__(self, value):
-        if not isinstance(value, basestring):
+        if not isinstance(value, str):
             raise TypeError('Value must be a string of binary data!')
 
         self.value = value
@@ -169,7 +169,7 @@
     This hook will transform Amazon DynamoDB JSON responses to something
     that maps directly to native Python types.
     """
-    if len(dct.keys()) > 1:
+    if len(list(dct.keys())) > 1:
         return dct
     if 'S' in dct:
         return dct['S']
@@ -244,23 +244,23 @@
                 n = str(float_to_decimal(attr))
             else:
                 n = str(DYNAMODB_CONTEXT.create_decimal(attr))
-            if filter(lambda x: x in n, ('Infinity', 'NaN')):
+            if [x for x in ('Infinity', 'NaN') if x in n]:
                 raise TypeError('Infinity and NaN not supported')
             return n
-        except (TypeError, DecimalException), e:
+        except (TypeError, DecimalException) as e:
             msg = '{0} numeric for `{1}`\n{2}'.format(
                 e.__class__.__name__, attr, str(e) or '')
         raise DynamoDBNumberError(msg)
 
     def _encode_s(self, attr):
-        if isinstance(attr, unicode):
+        if isinstance(attr, str):
             attr = attr.encode('utf-8')
         elif not isinstance(attr, str):
             attr = str(attr)
         return attr
 
     def _encode_ns(self, attr):
-        return map(self._encode_n, attr)
+        return list(map(self._encode_n, attr))
 
     def _encode_ss(self, attr):
         return [self._encode_s(n) for n in attr]
@@ -279,7 +279,7 @@
         """
         if len(attr) > 1 or not attr:
             return attr
-        dynamodb_type = attr.keys()[0]
+        dynamodb_type = list(attr.keys())[0]
         if dynamodb_type.lower() == dynamodb_type:
             # It's not an actual type, just a single character attr that
             # overlaps with the DDB types. Return it.
--- dynamodb2/items.py	(original)
+++ dynamodb2/items.py	(refactored)
@@ -90,13 +90,13 @@
         del self._data[key]
 
     def keys(self):
-        return self._data.keys()
+        return list(self._data.keys())
 
     def values(self):
-        return self._data.values()
+        return list(self._data.values())
 
     def items(self):
-        return self._data.items()
+        return list(self._data.items())
 
     def get(self, key, default=None):
         return self._data.get(key, default)
@@ -108,7 +108,7 @@
     def __contains__(self, key):
         return key in self._data
 
-    def __nonzero__(self):
+    def __bool__(self):
         return bool(self._data)
 
     def _determine_alterations(self):
@@ -214,7 +214,7 @@
         """
         self._data = {}
 
-        for field_name, field_value in data.get('Item', {}).items():
+        for field_name, field_value in list(data.get('Item', {}).items()):
             self[field_name] = self._dynamizer.decode(field_value)
 
         self._loaded = True
@@ -242,7 +242,7 @@
         """
         raw_key_data = {}
 
-        for key, value in self.get_keys().items():
+        for key, value in list(self.get_keys().items()):
             raw_key_data[key] = self._dynamizer.encode(value)
 
         return raw_key_data
@@ -256,7 +256,7 @@
         expects = {}
 
         if fields is None:
-            fields = self._data.keys() + self._orig_data.keys()
+            fields = list(self._data.keys()) + list(self._orig_data.keys())
 
         # Only uniques.
         fields = set(fields)
@@ -319,7 +319,7 @@
         # and hand-off to the table to handle creation/update.
         final_data = {}
 
-        for key, value in self._data.items():
+        for key, value in list(self._data.items()):
             if not self._is_storable(value):
                 continue
 
@@ -341,14 +341,14 @@
         fields = set()
         alterations = self._determine_alterations()
 
-        for key, value in alterations['adds'].items():
+        for key, value in list(alterations['adds'].items()):
             final_data[key] = {
                 'Action': 'PUT',
                 'Value': self._dynamizer.encode(self._data[key])
             }
             fields.add(key)
 
-        for key, value in alterations['changes'].items():
+        for key, value in list(alterations['changes'].items()):
             final_data[key] = {
                 'Action': 'PUT',
                 'Value': self._dynamizer.encode(self._data[key])
@@ -392,7 +392,7 @@
         # Remove the key(s) from the ``final_data`` if present.
         # They should only be present if this is a new item, in which
         # case we shouldn't be sending as part of the data to update.
-        for fieldname, value in key.items():
+        for fieldname, value in list(key.items()):
             if fieldname in final_data:
                 del final_data[fieldname]
 
--- dynamodb2/results.py	(original)
+++ dynamodb2/results.py	(refactored)
@@ -1,3 +1,4 @@
+import collections
 class ResultSet(object):
     """
     A class used to lazily handle page-to-page navigation through a set of
@@ -52,7 +53,7 @@
     def __iter__(self):
         return self
 
-    def next(self):
+    def __next__(self):
         self._offset += 1
 
         if self._offset >= len(self._results):
@@ -96,7 +97,7 @@
             >>> rs.to_call(squares_to, y=3)
 
         """
-        if not callable(the_callable):
+        if not isinstance(the_callable, collections.Callable):
             raise ValueError(
                 'You must supply an object or function to be called.'
             )
--- dynamodb2/table.py	(original)
+++ dynamodb2/table.py	(refactored)
@@ -388,7 +388,7 @@
         if global_indexes:
             gsi_data = []
 
-            for gsi_name, gsi_throughput in global_indexes.items():
+            for gsi_name, gsi_throughput in list(global_indexes.items()):
                 gsi_data.append({
                     "Update": {
                         "IndexName": gsi_name,
@@ -445,7 +445,7 @@
         """
         raw_key = {}
 
-        for key, value in keys.items():
+        for key, value in list(keys.items()):
             raw_key[key] = self._dynamizer.encode(value)
 
         return raw_key
@@ -567,7 +567,7 @@
         for x, arg in enumerate(args):
             kwargs[self.schema[x].name] = arg
         ret = self.get_item(**kwargs)
-        if not ret.keys():
+        if not list(ret.keys()):
             return None
         return ret
 
@@ -762,7 +762,7 @@
 
         filters = {}
 
-        for field_and_op, value in filter_kwargs.items():
+        for field_and_op, value in list(filter_kwargs.items()):
             field_bits = field_and_op.split('__')
             fieldname = '__'.join(field_bits[:-1])
 
@@ -1062,7 +1062,7 @@
         if exclusive_start_key:
             kwargs['exclusive_start_key'] = {}
 
-            for key, value in exclusive_start_key.items():
+            for key, value in list(exclusive_start_key.items()):
                 kwargs['exclusive_start_key'][key] = \
                     self._dynamizer.encode(value)
 
@@ -1094,7 +1094,7 @@
         if raw_results.get('LastEvaluatedKey', None):
             last_key = {}
 
-            for key, value in raw_results['LastEvaluatedKey'].items():
+            for key, value in list(raw_results['LastEvaluatedKey'].items()):
                 last_key[key] = self._dynamizer.decode(value)
 
         return {
@@ -1198,7 +1198,7 @@
         if exclusive_start_key:
             kwargs['exclusive_start_key'] = {}
 
-            for key, value in exclusive_start_key.items():
+            for key, value in list(exclusive_start_key.items()):
                 kwargs['exclusive_start_key'][key] = \
                     self._dynamizer.encode(value)
 
@@ -1225,7 +1225,7 @@
         if raw_results.get('LastEvaluatedKey', None):
             last_key = {}
 
-            for key, value in raw_results['LastEvaluatedKey'].items():
+            for key, value in list(raw_results['LastEvaluatedKey'].items()):
                 last_key[key] = self._dynamizer.decode(value)
 
         return {
@@ -1290,7 +1290,7 @@
         for key_data in keys:
             raw_key = {}
 
-            for key, value in key_data.items():
+            for key, value in list(key_data.items()):
                 raw_key[key] = self._dynamizer.encode(value)
 
             items[self.table_name]['Keys'].append(raw_key)
@@ -1311,7 +1311,7 @@
         for raw_key in raw_unproccessed.get('Keys', []):
             py_key = {}
 
-            for key, value in raw_key.items():
+            for key, value in list(raw_key.items()):
                 py_key[key] = self._dynamizer.decode(value)
 
             unprocessed_keys.append(py_key)
--- ec2/buyreservation.py	(original)
+++ ec2/buyreservation.py	(refactored)
@@ -66,19 +66,19 @@
     obj.get(params)
     offerings = obj.ec2.get_all_reserved_instances_offerings(instance_type=params['instance_type'],
                                                              availability_zone=params['zone'].name)
-    print '\nThe following Reserved Instances Offerings are available:\n'
+    print('\nThe following Reserved Instances Offerings are available:\n')
     for offering in offerings:
         offering.describe()
     prop = StringProperty(name='offering', verbose_name='Offering',
                           choices=offerings)
     offering = propget.get(prop)
-    print '\nYou have chosen this offering:'
+    print('\nYou have chosen this offering:')
     offering.describe()
     unit_price = float(offering.fixed_price)
     total_price = unit_price * params['quantity']
-    print '!!! You are about to purchase %d of these offerings for a total of $%.2f !!!' % (params['quantity'], total_price)
-    answer = raw_input('Are you sure you want to do this?  If so, enter YES: ')
+    print('!!! You are about to purchase %d of these offerings for a total of $%.2f !!!' % (params['quantity'], total_price))
+    answer = input('Are you sure you want to do this?  If so, enter YES: ')
     if answer.strip().lower() == 'yes':
         offering.purchase(params['quantity'])
     else:
-        print 'Purchase cancelled'
+        print('Purchase cancelled')
--- ec2/connection.py	(original)
+++ ec2/connection.py	(refactored)
@@ -2804,7 +2804,7 @@
                 keynames=[keyname],
                 dry_run=dry_run
             )[0]
-        except self.ResponseError, e:
+        except self.ResponseError as e:
             if e.code == 'InvalidKeyPair.NotFound':
                 return None
             else:
--- ec2/keypair.py	(original)
+++ ec2/keypair.py	(refactored)
@@ -83,7 +83,7 @@
             fp = open(file_path, 'wb')
             fp.write(self.material)
             fp.close()
-            os.chmod(file_path, 0600)
+            os.chmod(file_path, 0o600)
             return True
         else:
             raise BotoClientError('KeyPair contains no material')
--- ec2/reservedinstance.py	(original)
+++ ec2/reservedinstance.py	(refactored)
@@ -82,13 +82,13 @@
             self.marketplace = True if value == 'true' else False
 
     def describe(self):
-        print 'ID=%s' % self.id
-        print '\tInstance Type=%s' % self.instance_type
-        print '\tZone=%s' % self.availability_zone
-        print '\tDuration=%s' % self.duration
-        print '\tFixed Price=%s' % self.fixed_price
-        print '\tUsage Price=%s' % self.usage_price
-        print '\tDescription=%s' % self.description
+        print('ID=%s' % self.id)
+        print('\tInstance Type=%s' % self.instance_type)
+        print('\tZone=%s' % self.availability_zone)
+        print('\tDuration=%s' % self.duration)
+        print('\tFixed Price=%s' % self.fixed_price)
+        print('\tUsage Price=%s' % self.usage_price)
+        print('\tDescription=%s' % self.description)
 
     def purchase(self, instance_count=1, dry_run=False):
         return self.connection.purchase_reserved_instance_offering(
--- ec2/autoscale/__init__.py	(original)
+++ ec2/autoscale/__init__.py	(refactored)
@@ -134,15 +134,15 @@
             ['us-east-1b',...]
         """
         # different from EC2 list params
-        for i in xrange(1, len(items) + 1):
+        for i in range(1, len(items) + 1):
             if isinstance(items[i - 1], dict):
-                for k, v in items[i - 1].iteritems():
+                for k, v in items[i - 1].items():
                     if isinstance(v, dict):
-                        for kk, vv in v.iteritems():
+                        for kk, vv in v.items():
                             params['%s.member.%d.%s.%s' % (label, i, k, kk)] = vv
                     else:
                         params['%s.member.%d.%s' % (label, i, k)] = v
-            elif isinstance(items[i - 1], basestring):
+            elif isinstance(items[i - 1], str):
                 params['%s.member.%d' % (label, i)] = items[i - 1]
 
     def _update_group(self, op, as_group):
--- ec2/cloudwatch/__init__.py	(original)
+++ ec2/cloudwatch/__init__.py	(refactored)
@@ -110,7 +110,7 @@
         for dim_name in dimension:
             dim_value = dimension[dim_name]
             if dim_value:
-                if isinstance(dim_value, basestring):
+                if isinstance(dim_value, str):
                     dim_value = [dim_value]
                 for value in dim_value:
                     params['%s.%d.Name' % (prefix, i+1)] = dim_name
@@ -121,12 +121,12 @@
                 i += 1
 
     def build_list_params(self, params, items, label):
-        if isinstance(items, basestring):
+        if isinstance(items, str):
             items = [items]
         for index, item in enumerate(items):
             i = index + 1
             if isinstance(item, dict):
-                for k, v in item.iteritems():
+                for k, v in item.items():
                     params[label % (i, 'Name')] = k
                     if v is not None:
                         params[label % (i, 'Value')] = v
@@ -136,7 +136,7 @@
     def build_put_params(self, params, name, value=None, timestamp=None,
                         unit=None, dimensions=None, statistics=None):
         args = (name, value, unit, dimensions, statistics, timestamp)
-        length = max(map(lambda a: len(a) if isinstance(a, list) else 1, args))
+        length = max([len(a) if isinstance(a, list) else 1 for a in args])
 
         def aslist(a):
             if isinstance(a, list):
@@ -145,7 +145,7 @@
                 return a
             return [a] * length
 
-        for index, (n, v, u, d, s, t) in enumerate(zip(*map(aslist, args))):
+        for index, (n, v, u, d, s, t) in enumerate(zip(*list(map(aslist, args)))):
             metric_data = {'MetricName': n}
 
             if timestamp:
@@ -171,7 +171,7 @@
             else:
                 raise Exception('Must specify a value or statistics to put.')
 
-            for key, val in metric_data.iteritems():
+            for key, val in metric_data.items():
                 params['MetricData.member.%d.%s' % (index + 1, key)] = val
 
     def get_metric_statistics(self, period, start_time, end_time, metric_name,
--- ec2/cloudwatch/alarm.py	(original)
+++ ec2/cloudwatch/alarm.py	(refactored)
@@ -57,7 +57,7 @@
                     '<':  'LessThanThreshold',
                     '<=': 'LessThanOrEqualToThreshold',
                }
-    _rev_cmp_map = dict((v, k) for (k, v) in _cmp_map.iteritems())
+    _rev_cmp_map = dict((v, k) for (k, v) in _cmp_map.items())
 
     def __init__(self, connection=None, name=None, metric=None,
                  namespace=None, statistic=None, comparison=None,
--- ec2/elb/__init__.py	(original)
+++ ec2/elb/__init__.py	(refactored)
@@ -100,7 +100,7 @@
         return ['ec2']
 
     def build_list_params(self, params, items, label):
-        if isinstance(items, basestring):
+        if isinstance(items, str):
             items = [items]
         for index, item in enumerate(items):
             params[label % (index + 1)] = item
@@ -623,7 +623,7 @@
         params = {'LoadBalancerName': lb_name,
                   'PolicyName': policy_name,
                   'PolicyTypeName': policy_type}
-        for index, (name, value) in enumerate(policy_attributes.iteritems(), 1):
+        for index, (name, value) in enumerate(iter(policy_attributes.items()), 1):
             params['PolicyAttributes.member.%d.AttributeName' % index] = name
             params['PolicyAttributes.member.%d.AttributeValue' % index] = value
         else:
--- ec2/elb/loadbalancer.py	(original)
+++ ec2/elb/loadbalancer.py	(refactored)
@@ -187,7 +187,7 @@
         :param zones: The name of the zone(s) to add.
 
         """
-        if isinstance(zones, basestring):
+        if isinstance(zones, str):
             zones = [zones]
         new_zones = self.connection.enable_availability_zones(self.name, zones)
         self.availability_zones = new_zones
@@ -200,7 +200,7 @@
         :param zones: The name of the zone(s) to add.
 
         """
-        if isinstance(zones, basestring):
+        if isinstance(zones, str):
             zones = [zones]
         new_zones = self.connection.disable_availability_zones(self.name, zones)
         self.availability_zones = new_zones
@@ -267,7 +267,7 @@
             to add to this load balancer.
 
         """
-        if isinstance(instances, basestring):
+        if isinstance(instances, str):
             instances = [instances]
         new_instances = self.connection.register_instances(self.name,
                                                            instances)
@@ -282,7 +282,7 @@
             to remove from this load balancer.
 
         """
-        if isinstance(instances, basestring):
+        if isinstance(instances, str):
             instances = [instances]
         new_instances = self.connection.deregister_instances(self.name,
                                                              instances)
@@ -381,7 +381,7 @@
         :param subnets: The name of the subnet(s) to add.
 
         """
-        if isinstance(subnets, basestring):
+        if isinstance(subnets, str):
             subnets = [subnets]
         new_subnets = self.connection.attach_lb_to_subnets(self.name, subnets)
         self.subnets = new_subnets
@@ -394,7 +394,7 @@
         :param subnets: The name of the subnet(s) to detach.
 
         """
-        if isinstance(subnets, basestring):
+        if isinstance(subnets, str):
             subnets = [subnets]
         new_subnets = self.connection.detach_lb_from_subnets(self.name, subnets)
         self.subnets = new_subnets
@@ -409,7 +409,7 @@
         :param security_groups: The name of the security group(s) to add.
 
         """
-        if isinstance(security_groups, basestring):
+        if isinstance(security_groups, str):
             security_groups = [security_groups]
         new_sgs = self.connection.apply_security_groups_to_lb(
                                          self.name, security_groups)
--- ecs/__init__.py	(original)
+++ ecs/__init__.py	(refactored)
@@ -23,7 +23,7 @@
 from boto.connection import AWSQueryConnection, AWSAuthConnection
 from boto.exception import BotoServerError
 import time
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import xml.sax
 from boto.ecs.item import ItemSet
 from boto import handler
--- ecs/item.py	(original)
+++ ecs/item.py	(refactored)
@@ -22,7 +22,7 @@
 
 import xml.sax
 import cgi
-from StringIO import StringIO
+from io import StringIO
 
 class ResponseGroup(xml.sax.ContentHandler):
     """A Generic "Response Group", which can
@@ -136,19 +136,19 @@
             self.curItem.endElement(name, value, connection)
         return None
 
-    def next(self):
+    def __next__(self):
         """Special paging functionality"""
         if self.iter is None:
             self.iter = iter(self.objs)
         try:
-            return self.iter.next()
+            return next(self.iter)
         except StopIteration:
             self.iter = None
             self.objs = []
             if int(self.page) < int(self.total_pages):
                 self.page += 1
                 self._connection.get_response(self.action, self.params, self.page, self)
-                return self.next()
+                return next(self)
             else:
                 raise
 
--- emr/__init__.py	(original)
+++ emr/__init__.py	(refactored)
@@ -26,9 +26,9 @@
 This module provies an interface to the Elastic MapReduce (EMR)
 service from AWS.
 """
-from connection import EmrConnection
-from step import Step, StreamingStep, JarStep
-from bootstrap_action import BootstrapAction
+from .connection import EmrConnection
+from .step import Step, StreamingStep, JarStep
+from .bootstrap_action import BootstrapAction
 from boto.regioninfo import RegionInfo, get_regions
 
 
--- emr/bootstrap_action.py	(original)
+++ emr/bootstrap_action.py	(refactored)
@@ -25,7 +25,7 @@
         self.name = name
         self.path = path
 
-        if isinstance(bootstrap_action_args, basestring):
+        if isinstance(bootstrap_action_args, str):
             bootstrap_action_args = [bootstrap_action_args]
 
         self.bootstrap_action_args = bootstrap_action_args
--- emr/connection.py	(original)
+++ emr/connection.py	(refactored)
@@ -281,7 +281,7 @@
                      value for that tag should be the empty string
                      (e.g. '') or None.
         """
-        assert isinstance(resource_id, basestring)
+        assert isinstance(resource_id, str)
         params = {
             'ResourceId': resource_id,
         }
@@ -333,7 +333,7 @@
         :type steps: list(boto.emr.Step)
         :param steps: A list of steps to add to the job
         """
-        if not isinstance(steps, types.ListType):
+        if not isinstance(steps, list):
             steps = [steps]
         params = {}
         params['JobFlowId'] = jobflow_id
@@ -356,7 +356,7 @@
         :type instance_groups: list(boto.emr.InstanceGroup)
         :param instance_groups: A list of instance groups to add to the job
         """
-        if not isinstance(instance_groups, types.ListType):
+        if not isinstance(instance_groups, list):
             instance_groups = [instance_groups]
         params = {}
         params['JobFlowId'] = jobflow_id
@@ -377,12 +377,12 @@
         :type new_sizes: list(int)
         :param new_sizes: A list of the new sizes for each instance group
         """
-        if not isinstance(instance_group_ids, types.ListType):
+        if not isinstance(instance_group_ids, list):
             instance_group_ids = [instance_group_ids]
-        if not isinstance(new_sizes, types.ListType):
+        if not isinstance(new_sizes, list):
             new_sizes = [new_sizes]
 
-        instance_groups = zip(instance_group_ids, new_sizes)
+        instance_groups = list(zip(instance_group_ids, new_sizes))
 
         params = {}
         for k, ig in enumerate(instance_groups):
@@ -524,7 +524,7 @@
             # Instance group args (for spot instances or a heterogenous cluster)
             list_args = self._build_instance_group_list_args(instance_groups)
             instance_params = dict(
-                ('Instances.%s' % k, v) for k, v in list_args.iteritems()
+                ('Instances.%s' % k, v) for k, v in list_args.items()
                 )
             params.update(instance_params)
 
@@ -553,7 +553,7 @@
             params['AdditionalInfo'] = additional_info
 
         if api_params:
-            for key, value in api_params.iteritems():
+            for key, value in api_params.items():
                 if value is None:
                     params.pop(key, None)
                 else:
@@ -641,27 +641,27 @@
         return step_params
 
     def _build_bootstrap_action_list(self, bootstrap_actions):
-        if not isinstance(bootstrap_actions, types.ListType):
+        if not isinstance(bootstrap_actions, list):
             bootstrap_actions = [bootstrap_actions]
 
         params = {}
         for i, bootstrap_action in enumerate(bootstrap_actions):
-            for key, value in bootstrap_action.iteritems():
+            for key, value in bootstrap_action.items():
                 params['BootstrapActions.member.%s.%s' % (i + 1, key)] = value
         return params
 
     def _build_step_list(self, steps):
-        if not isinstance(steps, types.ListType):
+        if not isinstance(steps, list):
             steps = [steps]
 
         params = {}
         for i, step in enumerate(steps):
-            for key, value in step.iteritems():
+            for key, value in step.items():
                 params['Steps.member.%s.%s' % (i+1, key)] = value
         return params
 
     def _build_string_list(self, field, items):
-        if not isinstance(items, types.ListType):
+        if not isinstance(items, list):
             items = [items]
 
         params = {}
@@ -673,7 +673,7 @@
         assert isinstance(tags, dict)
 
         params = {}
-        for i, key_value in enumerate(sorted(tags.iteritems()), start=1):
+        for i, key_value in enumerate(sorted(tags.items()), start=1):
             key, value = key_value
             current_prefix = 'Tags.member.%s' % i
             params['%s.Key' % current_prefix] = key
@@ -734,12 +734,12 @@
         a comparable dict for use in making a RunJobFlow or AddInstanceGroups
         request.
         """
-        if not isinstance(instance_groups, types.ListType):
+        if not isinstance(instance_groups, list):
             instance_groups = [instance_groups]
 
         params = {}
         for i, instance_group in enumerate(instance_groups):
             ig_dict = self._build_instance_group_args(instance_group)
-            for key, value in ig_dict.iteritems():
+            for key, value in ig_dict.items():
                 params['InstanceGroups.member.%d.%s' % (i+1, key)] = value
         return params
--- emr/step.py	(original)
+++ emr/step.py	(refactored)
@@ -73,7 +73,7 @@
         self._main_class = main_class
         self.action_on_failure = action_on_failure
 
-        if isinstance(step_args, basestring):
+        if isinstance(step_args, str):
             step_args = [step_args]
 
         self.step_args = step_args
@@ -143,7 +143,7 @@
         self.output = output
         self._jar = jar
 
-        if isinstance(step_args, basestring):
+        if isinstance(step_args, str):
             step_args = [step_args]
 
         self.step_args = step_args
--- exception.py	(original)
+++ exception.py	(refactored)
@@ -31,7 +31,7 @@
 from boto.resultset import ResultSet
 
 
-class BotoClientError(StandardError):
+class BotoClientError(Exception):
     """
     General Boto Client error (error accessing AWS)
     """
@@ -46,7 +46,7 @@
         return 'BotoClientError: %s' % self.reason
 
 
-class SDBPersistenceError(StandardError):
+class SDBPersistenceError(Exception):
     pass
 
 
@@ -71,7 +71,7 @@
     pass
 
 
-class BotoServerError(StandardError):
+class BotoServerError(Exception):
     def __init__(self, status, reason, body=None, *args):
         super(BotoServerError, self).__init__(status, reason, body, *args)
         self.status = status
@@ -103,7 +103,7 @@
                 try:
                     h = handler.XmlHandlerWrapper(self, self)
                     h.parseString(self.body)
-                except (TypeError, xml.sax.SAXParseException), pe:
+                except (TypeError, xml.sax.SAXParseException) as pe:
                     # What if it's JSON? Let's try that.
                     try:
                         parsed = json.loads(self.body)
--- file/__init__.py	(original)
+++ file/__init__.py	(refactored)
@@ -21,8 +21,8 @@
 
 import boto
 
-from connection import FileConnection as Connection
-from key import Key
-from bucket import Bucket
+from .connection import FileConnection as Connection
+from .key import Key
+from .bucket import Bucket
 
 __all__ = ['Connection', 'Key', 'Bucket']
--- file/bucket.py	(original)
+++ file/bucket.py	(refactored)
@@ -23,7 +23,7 @@
 # File representation of bucket, for use with "file://" URIs.
 
 import os
-from key import Key
+from .key import Key
 from boto.file.simpleresultset import SimpleResultSet
 from boto.s3.bucketlistresultset import BucketListResultSet
 
--- file/connection.py	(original)
+++ file/connection.py	(refactored)
@@ -21,7 +21,7 @@
 
 # File representation of connection, for use with "file://" URIs.
 
-from bucket import Bucket
+from .bucket import Bucket
 
 class FileConnection(object):
 
--- file/key.py	(original)
+++ file/key.py	(refactored)
@@ -22,7 +22,7 @@
 
 # File representation of key, for use with "file://" URIs.
 
-import os, shutil, StringIO
+import os, shutil, io
 import sys
 
 class Key(object):
@@ -182,7 +182,7 @@
         :returns: The contents of the file as a string
         """
 
-        fp = StringIO.StringIO()
+        fp = io.StringIO()
         self.get_contents_to_file(fp)
         return fp.getvalue()
 
--- fps/connection.py	(original)
+++ fps/connection.py	(refactored)
@@ -21,7 +21,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import uuid
 from boto.connection import AWSQueryConnection
 from boto.fps.exception import ResponseErrorFactory
@@ -59,8 +59,8 @@
     def decorator(func):
 
         def wrapper(*args, **kw):
-            hasgroup = lambda x: len(x) == len(filter(kw.has_key, x))
-            if 1 != len(filter(hasgroup, groups)):
+            hasgroup = lambda x: len(x) == len(list(filter(kw.has_key, x)))
+            if 1 != len(list(filter(hasgroup, groups))):
                 message = ' OR '.join(['+'.join(g) for g in groups])
                 message = "{0} requires {1} argument(s)" \
                           "".format(getattr(func, 'action', 'Method'), message)
@@ -86,7 +86,7 @@
 def api_action(*api):
 
     def decorator(func):
-        action = ''.join(api or map(str.capitalize, func.func_name.split('_')))
+        action = ''.join(api or list(map(str.capitalize, func.__name__.split('_'))))
         response = ResponseFactory(action)
         if hasattr(boto.fps.response, action + 'Response'):
             response = getattr(boto.fps.response, action + 'Response')
@@ -212,8 +212,8 @@
         kw.setdefault('callerKey', self.aws_access_key_id)
 
         safestr = lambda x: x is not None and str(x) or ''
-        safequote = lambda x: urllib.quote(safestr(x), safe='~')
-        payload = sorted([(k, safequote(v)) for k, v in kw.items()])
+        safequote = lambda x: urllib.parse.quote(safestr(x), safe='~')
+        payload = sorted([(k, safequote(v)) for k, v in list(kw.items())])
 
         encoded = lambda p: '&'.join([k + '=' + v for k, v in p])
         canonical = '\n'.join(['GET', endpoint, base, encoded(payload)])
--- fps/response.py	(original)
+++ fps/response.py	(refactored)
@@ -49,7 +49,7 @@
     def __repr__(self):
         render = lambda pair: '{!s}: {!r}'.format(*pair)
         do_show = lambda pair: not pair[0].startswith('_')
-        attrs = filter(do_show, self.__dict__.items())
+        attrs = list(filter(do_show, list(self.__dict__.items())))
         return '{0}({1})'.format(self.__class__.__name__,
                                ', '.join(map(render, attrs)))
 
--- glacier/concurrent.py	(original)
+++ glacier/concurrent.py	(refactored)
@@ -19,7 +19,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 #
-from __future__ import with_statement
+
 
 import os
 import math
@@ -27,7 +27,7 @@
 import hashlib
 import time
 import logging
-from Queue import Queue, Empty
+from queue import Queue, Empty
 import binascii
 
 from .utils import DEFAULT_PART_SIZE, minimum_part_size, chunk_hashes, \
@@ -68,9 +68,9 @@
 
     def _add_work_items_to_queue(self, total_parts, worker_queue, part_size):
         log.debug("Adding work items to queue.")
-        for i in xrange(total_parts):
+        for i in range(total_parts):
             worker_queue.put((i, part_size))
-        for i in xrange(self._num_threads):
+        for i in range(self._num_threads):
             worker_queue.put(_END_SENTINEL)
 
 
@@ -146,7 +146,7 @@
         try:
             self._wait_for_upload_threads(hash_chunks, result_queue,
                                           total_parts)
-        except UploadArchiveError, e:
+        except UploadArchiveError as e:
             log.debug("An error occurred while uploading an archive, "
                       "aborting multipart upload.")
             self._api.abort_multipart_upload(self._vault_name, upload_id)
@@ -159,7 +159,7 @@
         return response['ArchiveId']
 
     def _wait_for_upload_threads(self, hash_chunks, result_queue, total_parts):
-        for _ in xrange(total_parts):
+        for _ in range(total_parts):
             result = result_queue.get()
             if isinstance(result, Exception):
                 log.debug("An error was found in the result queue, terminating "
@@ -177,7 +177,7 @@
     def _start_upload_threads(self, result_queue, upload_id, worker_queue,
                               filename):
         log.debug("Starting threads.")
-        for _ in xrange(self._num_threads):
+        for _ in range(self._num_threads):
             thread = UploadWorkerThread(self._api, self._vault_name, filename,
                                         upload_id, worker_queue, result_queue)
             time.sleep(0.2)
@@ -231,11 +231,11 @@
 
     def _process_chunk(self, work):
         result = None
-        for i in xrange(self._num_retries + 1):
+        for i in range(self._num_retries + 1):
             try:
                 result = self._upload_chunk(work)
                 break
-            except self._retry_exceptions, e:
+            except self._retry_exceptions as e:
                 log.error("Exception caught uploading part number %s for "
                           "vault %s, attempt: (%s / %s), filename: %s, "
                           "exception: %s, msg: %s",
@@ -306,7 +306,7 @@
         self._start_download_threads(result_queue, worker_queue)
         try:
             self._wait_for_download_threads(filename, result_queue, total_parts)
-        except DownloadArchiveError, e:
+        except DownloadArchiveError as e:
             log.debug("An error occurred while downloading an archive: %s", e)
             raise e
         log.debug("Download completed.")
@@ -324,7 +324,7 @@
         """
         hash_chunks = [None] * total_parts
         with open(filename, "wb") as f:
-            for _ in xrange(total_parts):
+            for _ in range(total_parts):
                 result = result_queue.get()
                 if isinstance(result, Exception):
                     log.debug("An error was found in the result queue, "
@@ -352,7 +352,7 @@
 
     def _start_download_threads(self, result_queue, worker_queue):
         log.debug("Starting threads.")
-        for _ in xrange(self._num_threads):
+        for _ in range(self._num_threads):
             thread = DownloadWorkerThread(self._job, worker_queue, result_queue)
             time.sleep(0.2)
             thread.start()
@@ -393,11 +393,11 @@
         :param work:
         """
         result = None
-        for _ in xrange(self._num_retries):
+        for _ in range(self._num_retries):
             try:
                 result = self._download_chunk(work)
                 break
-            except self._retry_exceptions, e:
+            except self._retry_exceptions as e:
                 log.error("Exception caught downloading part number %s for "
                           "job %s", work[0], self._job,)
                 time.sleep(self._time_between_retries)
--- glacier/job.py	(original)
+++ glacier/job.py	(refactored)
@@ -20,7 +20,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 #
-from __future__ import with_statement
+
 import math
 import socket
 
@@ -146,7 +146,7 @@
 
     def _download_to_fileob(self, fileobj, num_chunks, chunk_size, verify_hashes,
                             retry_exceptions):
-        for i in xrange(num_chunks):
+        for i in range(num_chunks):
             byte_range = ((i * chunk_size), ((i + 1) * chunk_size) - 1)
             data, expected_tree_hash = self._download_byte_range(
                 byte_range, retry_exceptions)
@@ -163,13 +163,13 @@
         # You can occasionally get socket.errors when downloading
         # chunks from Glacier, so each chunk can be retried up
         # to 5 times.
-        for _ in xrange(5):
+        for _ in range(5):
             try:
                 response = self.get_output(byte_range)
                 data = response.read()
                 expected_tree_hash = response['TreeHash']
                 return data, expected_tree_hash
-            except retry_exceptions, e:
+            except retry_exceptions as e:
                 continue
         else:
             raise DownloadArchiveError("There was an error downloading"
--- glacier/layer1.py	(original)
+++ glacier/layer1.py	(refactored)
@@ -650,8 +650,8 @@
 
         """
         uri = 'vaults/%s/jobs' % vault_name
-        response_headers = [('x-amz-job-id', u'JobId'),
-                            ('Location', u'Location')]
+        response_headers = [('x-amz-job-id', 'JobId'),
+                            ('Location', 'Location')]
         json_job_data = json.dumps(job_data)
         return self.make_request('POST', uri, data=json_job_data,
                                  ok_responses=(202,),
@@ -727,9 +727,9 @@
             "Range: bytes=0-1048575". By default, this operation downloads the
             entire output.
         """
-        response_headers = [('x-amz-sha256-tree-hash', u'TreeHash'),
-                            ('Content-Range', u'ContentRange'),
-                            ('Content-Type', u'ContentType')]
+        response_headers = [('x-amz-sha256-tree-hash', 'TreeHash'),
+                            ('Content-Range', 'ContentRange'),
+                            ('Content-Type', 'ContentType')]
         headers = None
         if byte_range:
             headers = {'Range': 'bytes=%d-%d' % byte_range}
@@ -806,9 +806,9 @@
         :param description: The optional description of the archive you
             are uploading.
         """
-        response_headers = [('x-amz-archive-id', u'ArchiveId'),
-                            ('Location', u'Location'),
-                            ('x-amz-sha256-tree-hash', u'TreeHash')]
+        response_headers = [('x-amz-archive-id', 'ArchiveId'),
+                            ('Location', 'Location'),
+                            ('x-amz-sha256-tree-hash', 'TreeHash')]
         uri = 'vaults/%s/archives' % vault_name
         try:
             content_length = str(len(archive))
@@ -937,8 +937,8 @@
         :param part_size: The size of each part except the last, in bytes. The
             last part can be smaller than this part size.
         """
-        response_headers = [('x-amz-multipart-upload-id', u'UploadId'),
-                            ('Location', u'Location')]
+        response_headers = [('x-amz-multipart-upload-id', 'UploadId'),
+                            ('Location', 'Location')]
         headers = {'x-amz-part-size': str(part_size)}
         if description:
             headers['x-amz-archive-description'] = description
@@ -1028,8 +1028,8 @@
             archive. This value should be the sum of all the sizes of
             the individual parts that you uploaded.
         """
-        response_headers = [('x-amz-archive-id', u'ArchiveId'),
-                            ('Location', u'Location')]
+        response_headers = [('x-amz-archive-id', 'ArchiveId'),
+                            ('Location', 'Location')]
         headers = {'x-amz-sha256-tree-hash': sha256_treehash,
                    'x-amz-archive-size': str(archive_size)}
         uri = 'vaults/%s/multipart-uploads/%s' % (vault_name, upload_id)
@@ -1271,7 +1271,7 @@
         headers = {'x-amz-content-sha256': linear_hash,
                    'x-amz-sha256-tree-hash': tree_hash,
                    'Content-Range': 'bytes %d-%d/*' % byte_range}
-        response_headers = [('x-amz-sha256-tree-hash', u'TreeHash')]
+        response_headers = [('x-amz-sha256-tree-hash', 'TreeHash')]
         uri = 'vaults/%s/multipart-uploads/%s' % (vault_name, upload_id)
         return self.make_request('PUT', uri, headers=headers,
                                  data=part_data, ok_responses=(204,),
--- glacier/response.py	(original)
+++ glacier/response.py	(refactored)
@@ -32,7 +32,7 @@
     def __init__(self, http_response, response_headers):
         self.http_response = http_response
         self.status = http_response.status
-        self[u'RequestId'] = http_response.getheader('x-amzn-requestid')
+        self['RequestId'] = http_response.getheader('x-amzn-requestid')
         if response_headers:
             for header_name, item_name in response_headers:
                 self[item_name] = http_response.getheader(header_name)
--- glacier/utils.py	(original)
+++ glacier/utils.py	(refactored)
@@ -71,7 +71,7 @@
 def chunk_hashes(bytestring, chunk_size=_MEGABYTE):
     chunk_count = int(math.ceil(len(bytestring) / float(chunk_size)))
     hashes = []
-    for i in xrange(chunk_count):
+    for i in range(chunk_count):
         start = i * chunk_size
         end = (i + 1) * chunk_size
         hashes.append(hashlib.sha256(bytestring[start:end]).digest())
--- glacier/vault.py	(original)
+++ glacier/vault.py	(refactored)
@@ -21,7 +21,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 #
-from __future__ import with_statement
+
 from .exceptions import UploadArchiveError
 from .job import Job
 from .writer import compute_hashes_from_fileobj, resume_file_upload, Writer
@@ -54,7 +54,7 @@
         if response_data:
             for response_name, attr_name, default in self.ResponseDataElements:
                 value = response_data[response_name]
-                if isinstance(value, unicode):
+                if isinstance(value, str):
                     value = value.encode('utf8')
                 setattr(self, attr_name, value)
         else:
--- gs/bucket.py	(original)
+++ gs/bucket.py	(refactored)
@@ -20,7 +20,7 @@
 # IN THE SOFTWARE.
 
 import re
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import xml.sax
 
 import boto
@@ -100,12 +100,12 @@
         if generation:
             query_args_l.append('generation=%s' % generation)
         if response_headers:
-            for rk, rv in response_headers.iteritems():
-                query_args_l.append('%s=%s' % (rk, urllib.quote(rv)))
+            for rk, rv in response_headers.items():
+                query_args_l.append('%s=%s' % (rk, urllib.parse.quote(rv)))
         try:
             key, resp = self._get_key_internal(key_name, headers,
                                                query_args_l=query_args_l)
-        except GSResponseError, e:
+        except GSResponseError as e:
             if e.status == 403 and 'Forbidden' in e.reason:
                 # If we failed getting an object, let the user know which object
                 # failed rather than just returning a generic 403.
--- gs/cors.py	(original)
+++ gs/cors.py	(refactored)
@@ -156,7 +156,7 @@
             s += '<' + collection + '>'
             # If collection elements has type string, append atomic value,
             # otherwise, append sequence of values in named tags.
-            if isinstance(elements_or_value, types.StringTypes):
+            if isinstance(elements_or_value, str):
               s += elements_or_value
             else:
               for (name, value) in elements_or_value:
--- gs/key.py	(original)
+++ gs/key.py	(refactored)
@@ -23,7 +23,7 @@
 import binascii
 import os
 import re
-import StringIO
+import io
 from boto.exception import BotoClientError
 from boto.s3.key import Key as S3Key
 from boto.s3.keyfile import KeyFile
@@ -704,7 +704,7 @@
         self.md5 = None
         self.base64md5 = None
 
-        fp = StringIO.StringIO(get_utf8_value(s))
+        fp = io.StringIO(get_utf8_value(s))
         r = self.set_contents_from_file(fp, headers, replace, cb, num_cb,
                                         policy, md5,
                                         if_generation=if_generation)
--- gs/resumable_upload_handler.py	(original)
+++ gs/resumable_upload_handler.py	(refactored)
@@ -20,13 +20,13 @@
 # IN THE SOFTWARE.
 
 import errno
-import httplib
+import http.client
 import os
 import random
 import re
 import socket
 import time
-import urlparse
+import urllib.parse
 from boto import config, UserAgent
 from boto.connection import AWSAuthConnection
 from boto.exception import InvalidUriError
@@ -58,7 +58,7 @@
 class ResumableUploadHandler(object):
 
     BUFFER_SIZE = 8192
-    RETRYABLE_EXCEPTIONS = (httplib.HTTPException, IOError, socket.error,
+    RETRYABLE_EXCEPTIONS = (http.client.HTTPException, IOError, socket.error,
                             socket.gaierror)
 
     # (start, end) response indicating server has nothing (upload protocol uses
@@ -98,20 +98,20 @@
             f = open(self.tracker_file_name, 'r')
             uri = f.readline().strip()
             self._set_tracker_uri(uri)
-        except IOError, e:
+        except IOError as e:
             # Ignore non-existent file (happens first time an upload
             # is attempted on a file), but warn user for other errors.
             if e.errno != errno.ENOENT:
                 # Will restart because self.tracker_uri is None.
-                print('Couldn\'t read URI tracker file (%s): %s. Restarting '
+                print(('Couldn\'t read URI tracker file (%s): %s. Restarting '
                       'upload from scratch.' %
-                      (self.tracker_file_name, e.strerror))
-        except InvalidUriError, e:
+                      (self.tracker_file_name, e.strerror)))
+        except InvalidUriError as e:
             # Warn user, but proceed (will restart because
             # self.tracker_uri is None).
-            print('Invalid tracker URI (%s) found in URI tracker file '
+            print(('Invalid tracker URI (%s) found in URI tracker file '
                   '(%s). Restarting upload from scratch.' %
-                  (uri, self.tracker_file_name))
+                  (uri, self.tracker_file_name)))
         finally:
             if f:
                 f.close()
@@ -125,9 +125,9 @@
         f = None
         try:
             with os.fdopen(os.open(self.tracker_file_name,
-                                   os.O_WRONLY | os.O_CREAT, 0600), 'w') as f:
+                                   os.O_WRONLY | os.O_CREAT, 0o600), 'w') as f:
               f.write(self.tracker_uri)
-        except IOError, e:
+        except IOError as e:
             raise ResumableUploadException(
                 'Couldn\'t write URI tracker file (%s): %s.\nThis can happen'
                 'if you\'re using an incorrectly configured upload tool\n'
@@ -143,7 +143,7 @@
 
         Raises InvalidUriError if URI is syntactically invalid.
         """
-        parse_result = urlparse.urlparse(uri)
+        parse_result = urllib.parse.urlparse(uri)
         if (parse_result.scheme.lower() not in ['http', 'https'] or
             not parse_result.netloc):
             raise InvalidUriError('Invalid tracker URI (%s)' % uri)
@@ -241,8 +241,8 @@
             # Parse 'bytes=<from>-<to>' range_spec.
             m = re.search('bytes=(\d+)-(\d+)', range_spec)
             if m:
-                server_start = long(m.group(1))
-                server_end = long(m.group(2))
+                server_start = int(m.group(1))
+                server_end = int(m.group(2))
                 got_valid_response = True
         else:
             # No Range header, which means the server does not yet have
@@ -256,7 +256,7 @@
                 'Couldn\'t parse upload server state query response (%s)' %
                 str(resp.getheaders()), ResumableTransferDisposition.START_OVER)
         if conn.debug >= 1:
-            print 'Server has: Range: %d - %d.' % (server_start, server_end)
+            print('Server has: Range: %d - %d.' % (server_start, server_end))
         return (server_start, server_end)
 
     def _start_new_resumable_upload(self, key, headers=None):
@@ -267,7 +267,7 @@
         """
         conn = key.bucket.connection
         if conn.debug >= 1:
-            print 'Starting new resumable upload.'
+            print('Starting new resumable upload.')
         self.server_has_bytes = 0
 
         # Start a new resumable upload by sending a POST request with an
@@ -433,7 +433,7 @@
                   # If the server already has some of the content, we need to
                   # update the digesters with the bytes that have already been
                   # uploaded to ensure we get a complete hash in the end.
-                  print 'Catching up hash digest(s) for resumed upload'
+                  print('Catching up hash digest(s) for resumed upload')
                   fp.seek(0)
                   # Read local file's bytes through position server has. For
                   # example, if server has (0, 3) we want to read 3-0+1=4 bytes.
@@ -453,10 +453,10 @@
                       bytes_to_go -= len(chunk)
 
                 if conn.debug >= 1:
-                    print 'Resuming transfer.'
-            except ResumableUploadException, e:
+                    print('Resuming transfer.')
+            except ResumableUploadException as e:
                 if conn.debug >= 1:
-                    print 'Unable to resume transfer (%s).' % e.message
+                    print('Unable to resume transfer (%s).' % e.message)
                 self._start_new_resumable_upload(key, headers)
         else:
             self._start_new_resumable_upload(key, headers)
@@ -513,7 +513,7 @@
         change some of the file and not realize they have inconsistent data.
         """
         if key.bucket.connection.debug >= 1:
-            print 'Checking md5 against etag.'
+            print('Checking md5 against etag.')
         if key.md5 != etag.strip('"\''):
             # Call key.open_read() before attempting to delete the
             # (incorrect-content) key, so we perform that request on a
@@ -531,19 +531,19 @@
     def handle_resumable_upload_exception(self, e, debug):
         if (e.disposition == ResumableTransferDisposition.ABORT_CUR_PROCESS):
             if debug >= 1:
-                print('Caught non-retryable ResumableUploadException (%s); '
-                      'aborting but retaining tracker file' % e.message)
+                print(('Caught non-retryable ResumableUploadException (%s); '
+                      'aborting but retaining tracker file' % e.message))
             raise
         elif (e.disposition == ResumableTransferDisposition.ABORT):
             if debug >= 1:
-                print('Caught non-retryable ResumableUploadException (%s); '
-                      'aborting and removing tracker file' % e.message)
+                print(('Caught non-retryable ResumableUploadException (%s); '
+                      'aborting and removing tracker file' % e.message))
             self._remove_tracker_file()
             raise
         else:
             if debug >= 1:
-                print('Caught ResumableUploadException (%s) - will retry' %
-                      e.message)
+                print(('Caught ResumableUploadException (%s) - will retry' %
+                      e.message))
 
     def track_progress_less_iterations(self, server_had_bytes_before_attempt,
                                        roll_back_md5=True, debug=0):
@@ -567,9 +567,9 @@
         # Use binary exponential backoff to desynchronize client requests.
         sleep_time_secs = random.random() * (2**self.progress_less_iterations)
         if debug >= 1:
-            print ('Got retryable failure (%d progress-less in a row).\n'
+            print(('Got retryable failure (%d progress-less in a row).\n'
                    'Sleeping %3.1f seconds before re-trying' %
-                   (self.progress_less_iterations, sleep_time_secs))
+                   (self.progress_less_iterations, sleep_time_secs)))
         time.sleep(sleep_time_secs)
 
     def send_file(self, key, fp, headers, cb=None, num_cb=10, hash_algs=None):
@@ -664,11 +664,11 @@
                 self._check_final_md5(key, etag)
                 key.generation = self.generation
                 if debug >= 1:
-                    print 'Resumable upload complete.'
+                    print('Resumable upload complete.')
                 return
-            except self.RETRYABLE_EXCEPTIONS, e:
+            except self.RETRYABLE_EXCEPTIONS as e:
                 if debug >= 1:
-                    print('Caught exception (%s)' % e.__repr__())
+                    print(('Caught exception (%s)' % e.__repr__()))
                 if isinstance(e, IOError) and e.errno == errno.EPIPE:
                     # Broken pipe error causes httplib to immediately
                     # close the socket (http://bugs.python.org/issue5542),
@@ -676,7 +676,7 @@
                     # the upload (which will cause a new connection to be
                     # opened the next time an HTTP request is sent).
                     key.bucket.connection.connection.close()
-            except ResumableUploadException, e:
+            except ResumableUploadException as e:
                 self.handle_resumable_upload_exception(e, debug)
 
             self.track_progress_less_iterations(server_had_bytes_before_attempt,
--- handler.py	(original)
+++ handler.py	(refactored)
@@ -19,7 +19,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-import StringIO
+import io
 import xml.sax
 
 class XmlHandler(xml.sax.ContentHandler):
@@ -55,4 +55,4 @@
         self.parser.setFeature(xml.sax.handler.feature_external_ges, 0)
 
     def parseString(self, content):
-        return self.parser.parse(StringIO.StringIO(content))
+        return self.parser.parse(io.StringIO(content))
--- https_connection.py	(original)
+++ https_connection.py	(refactored)
@@ -19,14 +19,14 @@
 
 """Extensions to allow HTTPS requests with SSL certificate validation."""
 
-import httplib
+import http.client
 import re
 import socket
 import ssl
 
 import boto
 
-class InvalidCertificateException(httplib.HTTPException):
+class InvalidCertificateException(http.client.HTTPException):
   """Raised when a certificate is provided with an invalid hostname."""
 
   def __init__(self, host, cert, reason):
@@ -36,7 +36,7 @@
       host: The hostname the connection was made to.
       cert: The SSL certificate (as a dictionary) the host returned.
     """
-    httplib.HTTPException.__init__(self)
+    http.client.HTTPException.__init__(self)
     self.host = host
     self.cert = cert
     self.reason = reason
@@ -79,10 +79,10 @@
   return False
 
 
-class CertValidatingHTTPSConnection(httplib.HTTPConnection):
+class CertValidatingHTTPSConnection(http.client.HTTPConnection):
   """An HTTPConnection that connects over SSL and validates certificates."""
 
-  default_port = httplib.HTTPS_PORT
+  default_port = http.client.HTTPS_PORT
 
   def __init__(self, host, port=default_port, key_file=None, cert_file=None,
                ca_certs=None, strict=None, **kwargs):
@@ -98,7 +98,7 @@
       strict: When true, causes BadStatusLine to be raised if the status line
           can't be parsed as a valid HTTP/1.0 or 1.1 status line.
     """
-    httplib.HTTPConnection.__init__(self, host, port, strict, **kwargs)
+    http.client.HTTPConnection.__init__(self, host, port, strict, **kwargs)
     self.key_file = key_file
     self.cert_file = cert_file
     self.ca_certs = ca_certs
--- iam/connection.py	(original)
+++ iam/connection.py	(refactored)
@@ -1104,13 +1104,13 @@
 
     def _build_policy(self, assume_role_policy_document=None):
         if assume_role_policy_document is not None:
-            if isinstance(assume_role_policy_document, basestring):
+            if isinstance(assume_role_policy_document, str):
                 # Historically, they had to pass a string. If it's a string,
                 # assume the user has already handled it.
                 return assume_role_policy_document
         else:
 
-            for tld, policy in DEFAULT_POLICY_DOCUMENTS.items():
+            for tld, policy in list(DEFAULT_POLICY_DOCUMENTS.items()):
                 if tld is 'default':
                     # Skip the default. We'll fall back to it if we don't find
                     # anything.
--- __init__.py	(original)
+++ __init__.py	(refactored)
@@ -34,7 +34,7 @@
 import sys
 import logging
 import logging.config
-import urlparse
+import urllib.parse
 from boto.exception import InvalidUriError
 
 __version__ = '2.29.1'
@@ -492,7 +492,7 @@
     """
     from boto.ec2.regioninfo import RegionInfo
 
-    purl = urlparse.urlparse(url)
+    purl = urllib.parse.urlparse(url)
     kwargs['port'] = purl.port
     kwargs['host'] = purl.hostname
     kwargs['path'] = purl.path
--- jsonresponse.py	(original)
+++ jsonresponse.py	(refactored)
@@ -21,7 +21,7 @@
 # IN THE SOFTWARE.
 
 import xml.sax
-import utils
+from . import utils
 
 class XmlHandler(xml.sax.ContentHandler):
 
--- manage/cmdshell.py	(original)
+++ manage/cmdshell.py	(refactored)
@@ -24,7 +24,7 @@
 import os
 import time
 import shutil
-import StringIO
+import io
 import paramiko
 import socket
 import subprocess
@@ -56,23 +56,24 @@
                                          pkey=self._pkey,
                                          timeout=self._timeout)
                 return
-            except socket.error, (value, message):
+            except socket.error as xxx_todo_changeme:
+                (value, message) = xxx_todo_changeme.args
                 if value in (51, 61, 111):
-                    print 'SSH Connection refused, will retry in 5 seconds'
+                    print('SSH Connection refused, will retry in 5 seconds')
                     time.sleep(5)
                     retry += 1
                 else:
                     raise
             except paramiko.BadHostKeyException:
-                print "%s has an entry in ~/.ssh/known_hosts and it doesn't match" % self.server.hostname
-                print 'Edit that file to remove the entry and then hit return to try again'
-                raw_input('Hit Enter when ready')
+                print("%s has an entry in ~/.ssh/known_hosts and it doesn't match" % self.server.hostname)
+                print('Edit that file to remove the entry and then hit return to try again')
+                input('Hit Enter when ready')
                 retry += 1
             except EOFError:
-                print 'Unexpected Error from SSH Connection, retry in 5 seconds'
+                print('Unexpected Error from SSH Connection, retry in 5 seconds')
                 time.sleep(5)
                 retry += 1
-        print 'Could not establish SSH connection'
+        print('Could not establish SSH connection')
 
     def open_sftp(self):
         return self._ssh_client.open_sftp()
@@ -179,7 +180,7 @@
 
     def run(self):
         boto.log.info('running:%s' % self.command)
-        log_fp = StringIO.StringIO()
+        log_fp = io.StringIO()
         process = subprocess.Popen(self.command, shell=True, stdin=subprocess.PIPE,
                                    stdout=subprocess.PIPE, stderr=subprocess.PIPE)
         while process.poll() is None:
--- manage/propget.py	(original)
+++ manage/propget.py	(refactored)
@@ -1,3 +1,4 @@
+import collections
 # Copyright (c) 2006-2009 Mitch Garnaat http://garnaat.org/
 #
 # Permission is hereby granted, free of charge, to any person obtaining a
@@ -25,7 +26,7 @@
     if not prompt:
         prompt = prop.name
     if choices:
-        if callable(choices):
+        if isinstance(choices, collections.Callable):
             choices = choices()
     else:
         choices = prop.get_choices()
@@ -38,8 +39,8 @@
                 value = choices[i-1]
                 if isinstance(value, tuple):
                     value = value[0]
-                print '[%d] %s' % (i, value)
-            value = raw_input('%s [%d-%d]: ' % (prompt, min, max))
+                print('[%d] %s' % (i, value))
+            value = input('%s [%d-%d]: ' % (prompt, min, max))
             try:
                 int_value = int(value)
                 value = choices[int_value-1]
@@ -47,18 +48,18 @@
                     value = value[1]
                 valid = True
             except ValueError:
-                print '%s is not a valid choice' % value
+                print('%s is not a valid choice' % value)
             except IndexError:
-                print '%s is not within the range[%d-%d]' % (min, max)
+                print('%s is not within the range[%d-%d]' % (min, max))
         else:
-            value = raw_input('%s: ' % prompt)
+            value = input('%s: ' % prompt)
             try:
                 value = prop.validate(value)
                 if prop.empty(value) and prop.required:
-                    print 'A value is required'
+                    print('A value is required')
                 else:
                     valid = True
             except:
-                print 'Invalid value: %s' % value
+                print('Invalid value: %s' % value)
     return value
         
--- manage/server.py	(original)
+++ manage/server.py	(refactored)
@@ -23,7 +23,7 @@
 """
 High-level abstraction of an EC2 server
 """
-from __future__ import with_statement
+
 import boto.ec2
 from boto.mashups.iobject import IObject
 from boto.pyami.config import BotoConfigPath, Config
@@ -32,7 +32,7 @@
 from boto.manage import propget
 from boto.ec2.zone import Zone
 from boto.ec2.keypair import KeyPair
-import os, time, StringIO
+import os, time, io
 from contextlib import closing
 from boto.exception import EC2ResponseError
 
@@ -49,7 +49,7 @@
         self.ssh_client = SSHClient(server, uname=uname)
 
     def copy_x509(self, key_file, cert_file):
-        print '\tcopying cert and pk over to /mnt directory on server'
+        print('\tcopying cert and pk over to /mnt directory on server')
         self.ssh_client.open_sftp()
         path, name = os.path.split(key_file)
         self.remote_key_file = '/mnt/%s' % name
@@ -57,7 +57,7 @@
         path, name = os.path.split(cert_file)
         self.remote_cert_file = '/mnt/%s' % name
         self.ssh_client.put_file(cert_file, self.remote_cert_file)
-        print '...complete!'
+        print('...complete!')
 
     def bundle_image(self, prefix, size, ssh_key):
         command = ""
@@ -103,7 +103,7 @@
             ssh_key = self.server.get_ssh_key_file()
         self.copy_x509(key_file, cert_file)
         if not fp:
-            fp = StringIO.StringIO()
+            fp = io.StringIO()
         fp.write('sudo mv %s /mnt/boto.cfg; ' % BotoConfigPath)
         fp.write('mv ~/.ssh/authorized_keys /mnt/authorized_keys; ')
         if clear_history:
@@ -115,13 +115,13 @@
         fp.write('sudo mv /mnt/boto.cfg %s; ' % BotoConfigPath)
         fp.write('mv /mnt/authorized_keys ~/.ssh/authorized_keys')
         command = fp.getvalue()
-        print 'running the following command on the remote server:'
-        print command
+        print('running the following command on the remote server:')
+        print(command)
         t = self.ssh_client.run(command)
-        print '\t%s' % t[0]
-        print '\t%s' % t[1]
-        print '...complete!'
-        print 'registering image...'
+        print('\t%s' % t[0])
+        print('\t%s' % t[1])
+        print('...complete!')
+        print('registering image...')
         self.image_id = self.server.ec2.register_image(name=prefix, image_location='%s/%s.manifest.xml' % (bucket, prefix))
         return self.image_id
 
@@ -137,7 +137,7 @@
 
     def get_region(self, params):
         region = params.get('region', None)
-        if isinstance(region, basestring):
+        if isinstance(region, str):
             region = boto.ec2.get_region(region)
             params['region'] = region
         if not region:
@@ -189,7 +189,7 @@
 
     def get_group(self, params):
         group = params.get('group', None)
-        if isinstance(group, basestring):
+        if isinstance(group, str):
             group_list = self.ec2.get_all_security_groups()
             for g in group_list:
                 if g.name == group:
@@ -202,7 +202,7 @@
 
     def get_key(self, params):
         keypair = params.get('keypair', None)
-        if isinstance(keypair, basestring):
+        if isinstance(keypair, str):
             key_list = self.ec2.get_all_key_pairs()
             for k in key_list:
                 if k.name == keypair:
@@ -305,7 +305,7 @@
         # deal with possibly passed in logical volume:
         if logical_volume != None:
            cfg.set('EBS', 'logical_volume_name', logical_volume.name)
-        cfg_fp = StringIO.StringIO()
+        cfg_fp = io.StringIO()
         cfg.write(cfg_fp)
         # deal with the possibility that zone and/or keypair are strings read from the config file:
         if isinstance(zone, Zone):
@@ -325,14 +325,14 @@
         instances = reservation.instances
         if elastic_ip is not None and instances.__len__() > 0:
             instance = instances[0]
-            print 'Waiting for instance to start so we can set its elastic IP address...'
+            print('Waiting for instance to start so we can set its elastic IP address...')
             # Sometimes we get a message from ec2 that says that the instance does not exist.
             # Hopefully the following delay will giv eec2 enough time to get to a stable state:
             time.sleep(5)
             while instance.update() != 'running':
                 time.sleep(1)
             instance.use_ip(elastic_ip)
-            print 'set the elastic IP of the first instance to %s' % elastic_ip
+            print('set the elastic IP of the first instance to %s' % elastic_ip)
         for instance in instances:
             s = cls()
             s.ec2 = ec2
@@ -381,7 +381,7 @@
             for reservation in rs:
                 for instance in reservation.instances:
                     try:
-                        Server.find(instance_id=instance.id).next()
+                        next(Server.find(instance_id=instance.id))
                         boto.log.info('Server for %s already exists' % instance.id)
                     except StopIteration:
                         s = cls()
@@ -527,7 +527,7 @@
 
     def get_cmdshell(self):
         if not self._cmdshell:
-            import cmdshell
+            from . import cmdshell
             self.get_ssh_key_file()
             self._cmdshell = cmdshell.start(self)
         return self._cmdshell
--- manage/task.py	(original)
+++ manage/task.py	(refactored)
@@ -23,7 +23,7 @@
 import boto
 from boto.sdb.db.property import StringProperty, DateTimeProperty, IntegerProperty
 from boto.sdb.db.model import Model
-import datetime, subprocess, StringIO, time
+import datetime, subprocess, io, time
 
 def check_hour(val):
     if val == '*':
@@ -100,7 +100,7 @@
 
     def _run(self, msg, vtimeout):
         boto.log.info('Task[%s] - running:%s' % (self.name, self.command))
-        log_fp = StringIO.StringIO()
+        log_fp = io.StringIO()
         process = subprocess.Popen(self.command, shell=True, stdin=subprocess.PIPE,
                                    stdout=subprocess.PIPE, stderr=subprocess.PIPE)
         nsecs = 5
--- manage/test_manage.py	(original)
+++ manage/test_manage.py	(refactored)
@@ -2,33 +2,33 @@
 from boto.manage.volume import Volume
 import time
 
-print '--> Creating New Volume'
+print('--> Creating New Volume')
 volume = Volume.create()
-print volume
+print(volume)
 
-print '--> Creating New Server'
+print('--> Creating New Server')
 server_list = Server.create()
 server = server_list[0]
-print server
+print(server)
 
-print '----> Waiting for Server to start up'
+print('----> Waiting for Server to start up')
 while server.status != 'running':
-    print '*'
+    print('*')
     time.sleep(10)
-print '----> Server is running'
+print('----> Server is running')
 
-print '--> Run "df -k" on Server'
+print('--> Run "df -k" on Server')
 status = server.run('df -k')
-print status[1]
+print(status[1])
 
-print '--> Now run volume.make_ready to make the volume ready to use on server'
+print('--> Now run volume.make_ready to make the volume ready to use on server')
 volume.make_ready(server)
 
-print '--> Run "df -k" on Server'
+print('--> Run "df -k" on Server')
 status = server.run('df -k')
-print status[1]
+print(status[1])
 
-print '--> Do an "ls -al" on the new filesystem'
+print('--> Do an "ls -al" on the new filesystem')
 status = server.run('ls -al %s' % volume.mount_point)
-print status[1]
+print(status[1])
 
--- manage/volume.py	(original)
+++ manage/volume.py	(refactored)
@@ -19,7 +19,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-from __future__ import with_statement
+
 from boto.sdb.db.model import Model
 from boto.sdb.db.property import StringProperty, IntegerProperty, ListProperty, ReferenceProperty, CalculatedProperty
 from boto.manage.server import Server
@@ -199,7 +199,7 @@
 
     def attach(self, server=None):
         if self.attachment_state == 'attached':
-            print 'already attached'
+            print('already attached')
             return None
         if server:
             self.server = server
@@ -210,7 +210,7 @@
     def detach(self, force=False):
         state = self.attachment_state
         if state == 'available' or state is None or state == 'detaching':
-            print 'already detached'
+            print('already detached')
             return None
         ec2 = self.get_ec2_connection()
         ec2.detach_volume(self.volume_id, self.server.instance_id, self.device, force)
@@ -353,9 +353,9 @@
                                      day=now.day, tzinfo=now.tzinfo)
         # Keep the first snapshot from each day of the previous week
         one_week = datetime.timedelta(days=7, seconds=60*60)
-        print midnight-one_week, midnight
+        print(midnight-one_week, midnight)
         previous_week = self.get_snapshot_range(snaps, midnight-one_week, midnight)
-        print previous_week
+        print(previous_week)
         if not previous_week:
             return snaps
         current_day = None
--- mashups/interactive.py	(original)
+++ mashups/interactive.py	(refactored)
@@ -51,7 +51,7 @@
                 try:
                     x = chan.recv(1024)
                     if len(x) == 0:
-                        print '\r\n*** EOF\r\n',
+                        print('\r\n*** EOF\r\n', end=' ')
                         break
                     sys.stdout.write(x)
                     sys.stdout.flush()
--- mashups/iobject.py	(original)
+++ mashups/iobject.py	(refactored)
@@ -33,31 +33,31 @@
     def choose_from_list(self, item_list, search_str='',
                          prompt='Enter Selection'):
         if not item_list:
-            print 'No Choices Available'
+            print('No Choices Available')
             return
         choice = None
         while not choice:
             n = 1
             choices = []
             for item in item_list:
-                if isinstance(item, basestring):
-                    print '[%d] %s' % (n, item)
+                if isinstance(item, str):
+                    print('[%d] %s' % (n, item))
                     choices.append(item)
                     n += 1
                 else:
                     obj, id, desc = item
                     if desc:
                         if desc.find(search_str) >= 0:
-                            print '[%d] %s - %s' % (n, id, desc)
+                            print('[%d] %s - %s' % (n, id, desc))
                             choices.append(obj)
                             n += 1
                     else:
                         if id.find(search_str) >= 0:
-                            print '[%d] %s' % (n, id)
+                            print('[%d] %s' % (n, id))
                             choices.append(obj)
                             n += 1
             if choices:
-                val = raw_input('%s[1-%d]: ' % (prompt, len(choices)))
+                val = input('%s[1-%d]: ' % (prompt, len(choices)))
                 if val.startswith('/'):
                     search_str = val[1:]
                 else:
@@ -67,23 +67,23 @@
                             return None
                         choice = choices[int_val-1]
                     except ValueError:
-                        print '%s is not a valid choice' % val
+                        print('%s is not a valid choice' % val)
                     except IndexError:
-                        print '%s is not within the range[1-%d]' % (val,
-                                                                    len(choices))
+                        print('%s is not within the range[1-%d]' % (val,
+                                                                    len(choices)))
             else:
-                print "No objects matched your pattern"
+                print("No objects matched your pattern")
                 search_str = ''
         return choice
 
     def get_string(self, prompt, validation_fn=None):
         okay = False
         while not okay:
-            val = raw_input('%s: ' % prompt)
+            val = input('%s: ' % prompt)
             if validation_fn:
                 okay = validation_fn(val)
                 if not okay:
-                    print 'Invalid value: %s' % val
+                    print('Invalid value: %s' % val)
             else:
                 okay = True
         return val
@@ -92,7 +92,7 @@
         okay = False
         val = ''
         while not okay:
-            val = raw_input('%s: %s' % (prompt, val))
+            val = input('%s: %s' % (prompt, val))
             val = os.path.expanduser(val)
             if os.path.isfile(val):
                 okay = True
@@ -105,7 +105,7 @@
                 else:
                     val = ''
             else:
-                print 'Invalid value: %s' % val
+                print('Invalid value: %s' % val)
                 val = ''
         return val
 
--- mashups/order.py	(original)
+++ mashups/order.py	(refactored)
@@ -29,7 +29,7 @@
 from boto.mashups.iobject import IObject
 from boto.pyami.config import Config
 from boto.sdb.persist import get_domain, set_domain
-import time, StringIO
+import time, io
 
 InstanceTypes = ['m1.small', 'm1.large', 'm1.xlarge', 'c1.medium', 'c1.xlarge']
 
@@ -124,7 +124,7 @@
         self.config = Config(path=config_path)
 
     def get_userdata_string(self):
-        s = StringIO.StringIO()
+        s = io.StringIO()
         self.config.write(s)
         return s.getvalue()
 
@@ -171,16 +171,16 @@
         self.items.append(item)
 
     def display(self):
-        print 'This Order consists of the following items'
-        print 
-        print 'QTY\tNAME\tTYPE\nAMI\t\tGroups\t\t\tKeyPair'
+        print('This Order consists of the following items')
+        print() 
+        print('QTY\tNAME\tTYPE\nAMI\t\tGroups\t\t\tKeyPair')
         for item in self.items:
-            print '%s\t%s\t%s\t%s\t%s\t%s' % (item.quantity, item.name, item.instance_type,
-                                              item.ami.id, item.groups, item.key.name)
+            print('%s\t%s\t%s\t%s\t%s\t%s' % (item.quantity, item.name, item.instance_type,
+                                              item.ami.id, item.groups, item.key.name))
 
     def place(self, block=True):
         if get_domain() is None:
-            print 'SDB Persistence Domain not set'
+            print('SDB Persistence Domain not set')
             domain_name = self.get_string('Specify SDB Domain')
             set_domain(domain_name)
         s = ServerSet()
@@ -192,7 +192,7 @@
             if block:
                 states = [i.state for i in r.instances]
                 if states.count('running') != len(states):
-                    print states
+                    print(states)
                     time.sleep(15)
                     states = [i.update() for i in r.instances]
             for i in r.instances:
--- mashups/server.py	(original)
+++ mashups/server.py	(refactored)
@@ -30,7 +30,8 @@
 from boto.sdb.db.model import Model
 from boto.sdb.db.property import StringProperty
 import os
-import StringIO
+import io
+import collections
 
 
 class ServerSet(list):
@@ -41,7 +42,7 @@
         for server in self:
             try:
                 val = getattr(server, name)
-                if callable(val):
+                if isinstance(val, collections.Callable):
                     is_callable = True
                 results.append(val)
             except:
@@ -228,7 +229,7 @@
             self._config.set('Pyami', 'server_sdb_domain', self._manager.domain.name)
             self._config.set("Pyami", 'server_sdb_name', self.name)
 
-        cfg = StringIO.StringIO()
+        cfg = io.StringIO()
         self._config.write(cfg)
         cfg = cfg.getvalue()
         r = ami.run(min_count=1,
@@ -252,7 +253,7 @@
                        uname='root'):
         import paramiko
         if not self.instance:
-            print 'No instance yet!'
+            print('No instance yet!')
             return
         if not self._ssh_client:
             if not key_file:
@@ -288,8 +289,8 @@
         interactive_shell(channel)
 
     def bundle_image(self, prefix, key_file, cert_file, size):
-        print 'bundling image...'
-        print '\tcopying cert and pk over to /mnt directory on server'
+        print('bundling image...')
+        print('\tcopying cert and pk over to /mnt directory on server')
         ssh_client = self.get_ssh_client()
         sftp_client = ssh_client.open_sftp()
         path, name = os.path.split(key_file)
@@ -298,7 +299,7 @@
         path, name = os.path.split(cert_file)
         remote_cert_file = '/mnt/%s' % name
         self.put_file(cert_file, remote_cert_file)
-        print '\tdeleting %s' % BotoConfigPath
+        print('\tdeleting %s' % BotoConfigPath)
         # delete the metadata.ini file if it exists
         try:
             sftp_client.remove(BotoConfigPath)
@@ -314,27 +315,27 @@
             command += '-r i386'
         else:
             command += '-r x86_64'
-        print '\t%s' % command
+        print('\t%s' % command)
         t = ssh_client.exec_command(command)
         response = t[1].read()
-        print '\t%s' % response
-        print '\t%s' % t[2].read()
-        print '...complete!'
+        print('\t%s' % response)
+        print('\t%s' % t[2].read())
+        print('...complete!')
 
     def upload_bundle(self, bucket, prefix):
-        print 'uploading bundle...'
+        print('uploading bundle...')
         command = 'ec2-upload-bundle '
         command += '-m /mnt/%s.manifest.xml ' % prefix
         command += '-b %s ' % bucket
         command += '-a %s ' % self.ec2.aws_access_key_id
         command += '-s %s ' % self.ec2.aws_secret_access_key
-        print '\t%s' % command
+        print('\t%s' % command)
         ssh_client = self.get_ssh_client()
         t = ssh_client.exec_command(command)
         response = t[1].read()
-        print '\t%s' % response
-        print '\t%s' % t[2].read()
-        print '...complete!'
+        print('\t%s' % response)
+        print('\t%s' % t[2].read())
+        print('...complete!')
 
     def create_image(self, bucket=None, prefix=None, key_file=None, cert_file=None, size=None):
         iobject = IObject()
@@ -350,7 +351,7 @@
             size = iobject.get_int('Size (in MB) of bundled image')
         self.bundle_image(prefix, key_file, cert_file, size)
         self.upload_bundle(bucket, prefix)
-        print 'registering image...'
+        print('registering image...')
         self.image_id = self.ec2.register_image('%s/%s.manifest.xml' % (bucket, prefix))
         return self.image_id
 
@@ -384,12 +385,12 @@
         return self.ec2.detach_volume(volume_id=volume_id, instance_id=self.instance_id)
 
     def install_package(self, package_name):
-        print 'installing %s...' % package_name
+        print('installing %s...' % package_name)
         command = 'yum -y install %s' % package_name
-        print '\t%s' % command
+        print('\t%s' % command)
         ssh_client = self.get_ssh_client()
         t = ssh_client.exec_command(command)
         response = t[1].read()
-        print '\t%s' % response
-        print '\t%s' % t[2].read()
-        print '...complete!'
+        print('\t%s' % response)
+        print('\t%s' % t[2].read())
+        print('...complete!')
--- mturk/connection.py	(original)
+++ mturk/connection.py	(refactored)
@@ -307,7 +307,7 @@
         records, return the page numbers to be retrieved.
         """
         pages = total_records / page_size + bool(total_records % page_size)
-        return range(1, pages + 1)
+        return list(range(1, pages + 1))
 
     def get_all_hits(self):
         """
@@ -323,7 +323,7 @@
         total_records = int(search_rs.TotalNumResults)
         get_page_hits = lambda page: self.search_hits(page_size=page_size, page_number=page)
         page_nums = self._get_pages(page_size, total_records)
-        hit_sets = itertools.imap(get_page_hits, page_nums)
+        hit_sets = map(get_page_hits, page_nums)
         return itertools.chain.from_iterable(hit_sets)
 
     def search_hits(self, sort_by='CreationTime', sort_direction='Ascending',
@@ -662,7 +662,7 @@
             params['TestDurationInSeconds'] = test_duration
 
         if answer_key is not None:
-            if isinstance(answer_key, basestring):
+            if isinstance(answer_key, str):
                 params['AnswerKey'] = answer_key  # xml
             else:
                 raise TypeError
@@ -691,7 +691,7 @@
         total_records = int(search_qual.TotalNumResults)
         get_page_quals = lambda page: self.get_qualifications_for_qualification_type(qualification_type_id = qualification_type_id, page_size=page_size, page_number = page)
         page_nums = self._get_pages(page_size, total_records)
-        qual_sets = itertools.imap(get_page_quals, page_nums)
+        qual_sets = map(get_page_quals, page_nums)
         return itertools.chain.from_iterable(qual_sets)
 
     def get_qualifications_for_qualification_type(self, qualification_type_id, page_size=100, page_number = 1):
@@ -730,7 +730,7 @@
             params['TestDurationInSeconds'] = test_duration
 
         if answer_key is not None:
-            if isinstance(answer_key, basestring):
+            if isinstance(answer_key, str):
                 params['AnswerKey'] = answer_key  # xml
             else:
                 raise TypeError
@@ -829,7 +829,7 @@
         """
         body = response.read()
         if self.debug == 2:
-            print body
+            print(body)
         if '<Errors>' not in body:
             rs = ResultSet(marker_elems)
             h = handler.XmlHandler(rs, self)
@@ -848,7 +848,7 @@
             keywords = ', '.join(keywords)
         if isinstance(keywords, str):
             final_keywords = keywords
-        elif isinstance(keywords, unicode):
+        elif isinstance(keywords, str):
             final_keywords = keywords.encode('utf-8')
         elif keywords is None:
             final_keywords = ""
--- mturk/question.py	(original)
+++ mturk/question.py	(refactored)
@@ -51,8 +51,8 @@
     class ValidatingXML(object):
 
         def validate(self):
-            import urllib2
-            schema_src_file = urllib2.urlopen(self.schema_url)
+            import urllib.request, urllib.error, urllib.parse
+            schema_src_file = urllib.request.urlopen(self.schema_url)
             schema_doc = etree.parse(schema_src_file)
             schema = etree.XMLSchema(schema_doc)
             doc = etree.fromstring(self.get_as_xml())
@@ -128,7 +128,7 @@
     def get_inner_content(self, content):
         content.append_field('Width', self.width)
         content.append_field('Height', self.height)
-        for name, value in self.parameters.items():
+        for name, value in list(self.parameters.items()):
             value = self.parameter_template % vars()
             content.append_field('ApplicationParameter', value)
 
@@ -286,7 +286,7 @@
 
 class Constraint(object):
     def get_attributes(self):
-        pairs = zip(self.attribute_names, self.attribute_values)
+        pairs = list(zip(self.attribute_names, self.attribute_values))
         attrs = ' '.join(
             '%s="%d"' % (name, value)
             for (name, value) in pairs
@@ -323,7 +323,7 @@
         self.attribute_values = pattern, error_text, flags
 
     def get_attributes(self):
-        pairs = zip(self.attribute_names, self.attribute_values)
+        pairs = list(zip(self.attribute_names, self.attribute_values))
         attrs = ' '.join(
             '%s="%s"' % (name, value)
             for (name, value) in pairs
--- mws/connection.py	(original)
+++ mws/connection.py	(refactored)
@@ -114,7 +114,7 @@
                 continue
             destructure_object(value[name], into, prefix + '.' + name,
                                members=members)
-    elif isinstance(value, basestring):
+    elif isinstance(value, str):
         into[prefix] = value
     elif isinstance(value, collections.Iterable):
         for index, element in enumerate(value):
@@ -148,8 +148,8 @@
     def decorator(func):
 
         def wrapper(*args, **kw):
-            hasgroup = lambda x: len(x) == len(filter(kw.has_key, x))
-            if 1 != len(filter(hasgroup, groups)):
+            hasgroup = lambda x: len(x) == len(list(filter(kw.has_key, x)))
+            if 1 != len(list(filter(hasgroup, groups))):
                 message = ' OR '.join(['+'.join(g) for g in groups])
                 message = "{0} requires {1} argument(s)" \
                           "".format(func.action, message)
@@ -167,8 +167,8 @@
     def decorator(func):
 
         def wrapper(*args, **kw):
-            hasgroup = lambda x: len(x) == len(filter(kw.has_key, x))
-            if len(filter(hasgroup, groups)) not in (0, 1):
+            hasgroup = lambda x: len(x) == len(list(filter(kw.has_key, x)))
+            if len(list(filter(hasgroup, groups))) not in (0, 1):
                 message = ' OR '.join(['+'.join(g) for g in groups])
                 message = "{0} requires either {1}" \
                           "".format(func.action, message)
@@ -186,8 +186,8 @@
     def decorator(func):
 
         def wrapper(*args, **kw):
-            hasgroup = lambda x: len(x) == len(filter(kw.has_key, x))
-            if field in kw and 1 > len(filter(hasgroup, groups)):
+            hasgroup = lambda x: len(x) == len(list(filter(kw.has_key, x)))
+            if field in kw and 1 > len(list(filter(hasgroup, groups))):
                 message = ' OR '.join(['+'.join(g) for g in groups])
                 message = "{0} argument {1} requires {2}" \
                           "".format(func.action, field, message)
@@ -206,7 +206,7 @@
     def decorator(func):
 
         def wrapper(*args, **kw):
-            if not filter(kw.has_key, fields):
+            if not list(filter(kw.has_key, fields)):
                 message = "{0} requires at least one of {1} argument(s)" \
                           "".format(func.action, ', '.join(fields))
                 raise KeyError(message)
@@ -235,7 +235,7 @@
 
     def decorator(func, quota=int(quota), restore=float(restore)):
         version, accesskey, path = api_version_path[section]
-        action = ''.join(api or map(str.capitalize, func.func_name.split('_')))
+        action = ''.join(api or list(map(str.capitalize, func.__name__.split('_'))))
 
         def wrapper(self, *args, **kw):
             kw.setdefault(accesskey, getattr(self, accesskey, None))
@@ -254,7 +254,7 @@
         wrapper.__doc__ = "MWS {0}/{1} API call; quota={2} restore={3:.2f}\n" \
                           "{4}".format(action, version, quota, restore,
                                        func.__doc__)
-        api_call_map[action] = func.func_name
+        api_call_map[action] = func.__name__
         return wrapper
     return decorator
 
@@ -273,12 +273,12 @@
         super(MWSConnection, self).__init__(*args, **kw)
 
     def _setup_factories(self, extrascopes, **kw):
-        for factory, (scope, Default) in {
+        for factory, (scope, Default) in list({
             'response_factory':
                 (boto.mws.response, self.ResponseFactory),
             'response_error_factory':
                 (boto.mws.exception, self.ResponseErrorFactory),
-        }.items():
+        }.items()):
             if factory in kw:
                 setattr(self, '_' + factory, kw.pop(factory))
             else:
@@ -307,7 +307,7 @@
                                                host=self.host)
         try:
             response = self._mexe(request, override_num_retries=None)
-        except BotoServerError, bs:
+        except BotoServerError as bs:
             raise self._response_error_factor(bs.status, bs.reason, bs.body)
         body = response.read()
         boto.log.debug(body)
@@ -416,7 +416,7 @@
     def get_service_status(self, **kw):
         """Instruct the user on how to get service status.
         """
-        sections = ', '.join(map(str.lower, api_version_path.keys()))
+        sections = ', '.join(map(str.lower, list(api_version_path.keys())))
         message = "Use {0}.get_(section)_service_status(), " \
                   "where (section) is one of the following: " \
                   "{1}".format(self.__class__.__name__, sections)
@@ -720,11 +720,11 @@
         toggle = set(('FulfillmentChannel.Channel.1',
                       'OrderStatus.Status.1', 'PaymentMethod.1',
                       'LastUpdatedAfter', 'LastUpdatedBefore'))
-        for do, dont in {
+        for do, dont in list({
             'BuyerEmail': toggle.union(['SellerOrderId']),
             'SellerOrderId': toggle.union(['BuyerEmail']),
-        }.items():
-            if do in kw and filter(kw.has_key, dont):
+        }.items()):
+            if do in kw and list(filter(kw.has_key, dont)):
                 message = "Don't include {0} when specifying " \
                           "{1}".format(' or '.join(dont), do)
                 raise AssertionError(message)
--- mws/exception.py	(original)
+++ mws/exception.py	(refactored)
@@ -27,7 +27,7 @@
     def __call__(self, status, reason, body=None):
         server = BotoServerError(status, reason, body=body)
         supplied = self.find_element(server.error_code, '', ResponseError)
-        print supplied.__name__
+        print(supplied.__name__)
         return supplied(status, reason, body=body)
 
 
--- mws/response.py	(original)
+++ mws/response.py	(refactored)
@@ -41,7 +41,7 @@
         self._hint = JITResponse
         self._hint.__name__ = 'JIT_{0}/{1}'.format(self.__class__.__name__,
                                                    hex(id(self._hint))[2:])
-        for name, value in kw.items():
+        for name, value in list(kw.items()):
             setattr(self._hint, name, value)
 
     def __repr__(self):
@@ -201,7 +201,7 @@
         scope = inherit(self.__class__)
         scope.update(self.__dict__)
         declared = lambda attr: isinstance(attr[1], DeclarativeType)
-        for name, node in filter(declared, scope.items()):
+        for name, node in filter(declared, list(scope.items())):
             getattr(node, op)(self, name, parentname=self._name, **kw)
 
     @property
@@ -211,7 +211,7 @@
     def __repr__(self):
         render = lambda pair: '{0!s}: {1!r}'.format(*pair)
         do_show = lambda pair: not pair[0].startswith('_')
-        attrs = filter(do_show, self.__dict__.items())
+        attrs = list(filter(do_show, list(self.__dict__.items())))
         name = self.__class__.__name__
         if name.startswith('JIT_'):
             name = '^{0}^'.format(self._name or '')
@@ -414,7 +414,7 @@
 
     def __repr__(self):
         values = [getattr(self, key, None) for key in self._dimensions]
-        values = filter(None, values)
+        values = [_f for _f in values if _f]
         return 'x'.join(map('{0.Value:0.2f}{0[Units]}'.format, values))
 
     @strip_namespace
--- provider.py	(original)
+++ provider.py	(refactored)
@@ -380,7 +380,7 @@
             data='meta-data/iam/security-credentials/')
         if metadata:
             # I'm assuming there's only one role on the instance profile.
-            security = metadata.values()[0]
+            security = list(metadata.values())[0]
             self._access_key = security['AccessKeyId']
             self._secret_key = self._convert_key_to_str(security['SecretAccessKey'])
             self._security_token = security['Token']
@@ -391,7 +391,7 @@
                            self._credential_expiry_time - datetime.now(), expires_at)
 
     def _convert_key_to_str(self, key):
-        if isinstance(key, unicode):
+        if isinstance(key, str):
             # the secret key must be bytes and not unicode to work
             #  properly with hmac.new (see http://bugs.python.org/issue5285)
             return str(key)
--- pyami/bootstrap.py	(original)
+++ pyami/bootstrap.py	(refactored)
@@ -82,7 +82,7 @@
                 try:
                     self.run('git pull', cwd=location)
                     num_remaining_attempts = 0
-                except Exception, e:
+                except Exception as e:
                     boto.log.info('git pull attempt failed with the following exception. Trying again in a bit. %s', e)
                     time.sleep(2)
             if update.find(':') >= 0:
--- pyami/config.py	(original)
+++ pyami/config.py	(refactored)
@@ -20,10 +20,10 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 #
-import ConfigParser
+import configparser
 import os
 import re
-import StringIO
+import io
 import warnings
 
 import boto
@@ -50,12 +50,12 @@
         BotoConfigLocations.append(expanduser(path))
 
 
-class Config(ConfigParser.SafeConfigParser):
+class Config(configparser.SafeConfigParser):
 
     def __init__(self, path=None, fp=None, do_load=True):
         # We don't use ``super`` here, because ``ConfigParser`` still uses
         # old-style classes.
-        ConfigParser.SafeConfigParser.__init__(self, {'working_dir' : '/mnt/pyami',
+        configparser.SafeConfigParser.__init__(self, {'working_dir' : '/mnt/pyami',
                                                       'debug' : '0'})
         if do_load:
             if path:
@@ -73,7 +73,7 @@
 
     def load_credential_file(self, path):
         """Load a credential file as is setup like the Java utilities"""
-        c_data = StringIO.StringIO()
+        c_data = io.StringIO()
         c_data.write("[Credentials]\n")
         for line in open(path, "r").readlines():
             c_data.write(line.replace("AWSAccessKeyId", "aws_access_key_id").replace("AWSSecretKey", "aws_secret_access_key"))
@@ -96,7 +96,7 @@
         Replace any previous value.  If the path doesn't exist, create it.
         Also add the option the the in-memory config.
         """
-        config = ConfigParser.SafeConfigParser()
+        config = configparser.SafeConfigParser()
         config.read(path)
         if not config.has_section(section):
             config.add_section(section)
@@ -140,21 +140,21 @@
 
     def get(self, section, name, default=None):
         try:
-            val = ConfigParser.SafeConfigParser.get(self, section, name)
+            val = configparser.SafeConfigParser.get(self, section, name)
         except:
             val = default
         return val
 
     def getint(self, section, name, default=0):
         try:
-            val = ConfigParser.SafeConfigParser.getint(self, section, name)
+            val = configparser.SafeConfigParser.getint(self, section, name)
         except:
             val = int(default)
         return val
 
     def getfloat(self, section, name, default=0.0):
         try:
-            val = ConfigParser.SafeConfigParser.getfloat(self, section, name)
+            val = configparser.SafeConfigParser.getfloat(self, section, name)
         except:
             val = float(default)
         return val
@@ -177,13 +177,13 @@
             self.set(section, name, 'false')
 
     def dump(self):
-        s = StringIO.StringIO()
+        s = io.StringIO()
         self.write(s)
-        print s.getvalue()
+        print(s.getvalue())
 
     def dump_safe(self, fp=None):
         if not fp:
-            fp = StringIO.StringIO()
+            fp = io.StringIO()
         for section in self.sections():
             fp.write('[%s]\n' % section)
             for option in self.options(section):
@@ -212,11 +212,11 @@
         sdb = boto.connect_sdb()
         domain = sdb.lookup(domain_name)
         item = domain.get_item(item_name)
-        for section in item.keys():
+        for section in list(item.keys()):
             if not self.has_section(section):
                 self.add_section(section)
             d = json.loads(item[section])
-            for attr_name in d.keys():
+            for attr_name in list(d.keys()):
                 attr_value = d[attr_name]
                 if attr_value is None:
                     attr_value = 'None'
--- pyami/copybot.py	(original)
+++ pyami/copybot.py	(refactored)
@@ -21,7 +21,7 @@
 #
 import boto
 from boto.pyami.scriptbase import ScriptBase
-import os, StringIO
+import os, io
 
 class CopyBot(ScriptBase):
 
@@ -82,7 +82,7 @@
         key.set_contents_from_filename(self.log_path)
 
     def main(self):
-        fp = StringIO.StringIO()
+        fp = io.StringIO()
         boto.config.dump_safe(fp)
         self.notify('%s (%s) Starting' % (self.name, self.instance_id), fp.getvalue())
         if self.src and self.dst:
--- pyami/launch_ami.py	(original)
+++ pyami/launch_ami.py	(refactored)
@@ -68,7 +68,7 @@
 """
 
 def usage():
-    print usage_string
+    print(usage_string)
     sys.exit()
 
 def main():
@@ -124,14 +124,14 @@
     required = ['ami']
     for pname in required:
         if not params.get(pname, None):
-            print '%s is required' % pname
+            print('%s is required' % pname)
             usage()
     if params['script_name']:
         # first copy the desired module file to S3 bucket
         if reload:
-            print 'Reloading module %s to S3' % params['script_name']
+            print('Reloading module %s to S3' % params['script_name'])
         else:
-            print 'Copying module %s to S3' % params['script_name']
+            print('Copying module %s to S3' % params['script_name'])
         l = imp.find_module(params['script_name'])
         c = boto.connect_s3()
         bucket = c.get_bucket(params['script_bucket'])
@@ -140,7 +140,7 @@
         params['script_md5'] = key.md5
     # we have everything we need, now build userdata string
     l = []
-    for k, v in params.items():
+    for k, v in list(params.items()):
         if v:
             l.append('%s=%s' % (k, v))
     c = boto.connect_ec2()
@@ -155,23 +155,23 @@
         r = img.run(user_data=s, key_name=params['keypair'],
                     security_groups=[params['group']],
                     max_count=params.get('num_instances', 1))
-        print 'AMI: %s - %s (Started)' % (params['ami'], img.location)
-        print 'Reservation %s contains the following instances:' % r.id
+        print('AMI: %s - %s (Started)' % (params['ami'], img.location))
+        print('Reservation %s contains the following instances:' % r.id)
         for i in r.instances:
-            print '\t%s' % i.id
+            print('\t%s' % i.id)
         if wait:
             running = False
             while not running:
                 time.sleep(30)
                 [i.update() for i in r.instances]
                 status = [i.state for i in r.instances]
-                print status
+                print(status)
                 if status.count('running') == len(r.instances):
                     running = True
             for i in r.instances:
-                print 'Instance: %s' % i.ami_launch_index
-                print 'Public DNS Name: %s' % i.public_dns_name
-                print 'Private DNS Name: %s' % i.private_dns_name
+                print('Instance: %s' % i.ami_launch_index)
+                print('Public DNS Name: %s' % i.public_dns_name)
+                print('Private DNS Name: %s' % i.private_dns_name)
 
 if __name__ == "__main__":
     main()
--- pyami/startup.py	(original)
+++ pyami/startup.py	(refactored)
@@ -44,7 +44,7 @@
                         s.main()
                     else:
                         boto.log.warning('Trouble parsing script: %s' % script)
-                except Exception, e:
+                except Exception as e:
                     boto.log.exception('Problem Running Script: %s. Startup process halting.' % script)
                     raise e
 
--- pyami/installers/ubuntu/ebs.py	(original)
+++ pyami/installers/ubuntu/ebs.py	(refactored)
@@ -114,7 +114,7 @@
         if self.logical_volume_name:
             # if a logical volume was specified, override the specified volume_id
             # (if there was one) with the current AWS volume for the logical volume:
-            logical_volume = Volume.find(name = self.logical_volume_name).next()
+            logical_volume = next(Volume.find(name = self.logical_volume_name))
             self.volume_id = logical_volume._volume_id
         volume = ec2.get_all_volumes([self.volume_id])[0]
         # wait for the volume to be available. The volume may still be being created
@@ -128,7 +128,7 @@
             try:
                 ec2.attach_volume(self.volume_id, self.instance_id, self.device)
                 attempt_attach = False
-            except EC2ResponseError, e:
+            except EC2ResponseError as e:
                 if e.error_code != 'IncorrectState':
                     # if there's an EC2ResonseError with the code set to IncorrectState, delay a bit for ec2
                     # to realize the instance is running, then try again. Otherwise, raise the error:
--- pyami/installers/ubuntu/installer.py	(original)
+++ pyami/installers/ubuntu/installer.py	(refactored)
@@ -43,7 +43,7 @@
             hour = str(random.randrange(24))
         fp = open('/etc/cron.d/%s' % name, "w")
         if env:
-            for key, value in env.items():
+            for key, value in list(env.items()):
                 fp.write('%s=%s\n' % (key, value))
         fp.write('%s %s %s %s %s %s %s\n' % (minute, hour, mday, month, wday, who, command))
         fp.close()
--- pyami/installers/ubuntu/mysql.py	(original)
+++ pyami/installers/ubuntu/mysql.py	(refactored)
@@ -31,7 +31,7 @@
 import os
 import boto
 from boto.utils import ShellCommand
-from ConfigParser import SafeConfigParser
+from configparser import SafeConfigParser
 import time
 
 ConfigSection = """
--- rds/__init__.py	(original)
+++ rds/__init__.py	(refactored)
@@ -20,7 +20,7 @@
 # IN THE SOFTWARE.
 #
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 from boto.connection import AWSQueryConnection
 from boto.rds.dbinstance import DBInstance
 from boto.rds.dbsecuritygroup import DBSecurityGroup
@@ -451,7 +451,7 @@
             self.build_list_params(params, l, 'VpcSecurityGroupIds.member')
 
         # Remove any params set to None
-        for k, v in params.items():
+        for k, v in list(params.items()):
           if v is None: del(params[k])
 
         return self.get_object('CreateDBInstance', params, DBInstance)
@@ -990,7 +990,7 @@
         if ec2_security_group_owner_id:
             params['EC2SecurityGroupOwnerId'] = ec2_security_group_owner_id
         if cidr_ip:
-            params['CIDRIP'] = urllib.quote(cidr_ip)
+            params['CIDRIP'] = urllib.parse.quote(cidr_ip)
         return self.get_object('AuthorizeDBSecurityGroupIngress', params,
                                DBSecurityGroup)
 
--- rds/parametergroup.py	(original)
+++ rds/parametergroup.py	(refactored)
@@ -133,7 +133,7 @@
             d[prefix+'ApplyMethod'] = self.apply_method
 
     def _set_string_value(self, value):
-        if not isinstance(value, basestring):
+        if not isinstance(value, str):
             raise ValueError('value must be of type str')
         if self.allowed_values:
             choices = self.allowed_values.split(',')
@@ -142,9 +142,9 @@
         self._value = value
 
     def _set_integer_value(self, value):
-        if isinstance(value, basestring):
+        if isinstance(value, str):
             value = int(value)
-        if isinstance(value, int) or isinstance(value, long):
+        if isinstance(value, int) or isinstance(value, int):
             if self.allowed_values:
                 min, max = self.allowed_values.split('-')
                 if value < int(min) or value > int(max):
@@ -156,7 +156,7 @@
     def _set_boolean_value(self, value):
         if isinstance(value, bool):
             self._value = value
-        elif isinstance(value, basestring):
+        elif isinstance(value, str):
             if value.lower() == 'true':
                 self._value = True
             else:
@@ -180,7 +180,7 @@
         if self.type == 'string':
             return self._value
         elif self.type == 'integer':
-            if not isinstance(self._value, int) and not isinstance(self._value, long):
+            if not isinstance(self._value, int) and not isinstance(self._value, int):
                 self._set_integer_value(self._value)
             return self._value
         elif self.type == 'boolean':
--- regioninfo.py	(original)
+++ regioninfo.py	(refactored)
@@ -20,7 +20,7 @@
 # WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
-from __future__ import with_statement
+
 import os
 
 import boto
@@ -58,7 +58,7 @@
     # We can't just do an ``defaults.update(...)`` here, as that could
     # *overwrite* regions if present in both.
     # We'll iterate instead, essentially doing a deeper merge.
-    for service, region_info in additions.items():
+    for service, region_info in list(additions.items()):
         # Set the default, if not present, to an empty dict.
         defaults.setdefault(service, {})
         defaults[service].update(region_info)
@@ -135,7 +135,7 @@
 
     region_objs = []
 
-    for region_name, endpoint in endpoints.get(service_name, {}).items():
+    for region_name, endpoint in list(endpoints.get(service_name, {}).items()):
         region_objs.append(
             region_cls(
                 name=region_name,
--- requestlog.py	(original)
+++ requestlog.py	(refactored)
@@ -1,7 +1,7 @@
 
 from datetime import datetime
 from threading import Thread
-import Queue
+import queue
 
 from boto.utils import RequestHook
 
@@ -12,7 +12,7 @@
     """
     def __init__(self, filename='/tmp/request_log.csv'):
         self.request_log_file = open(filename, 'w')
-        self.request_log_queue = Queue.Queue(100)
+        self.request_log_queue = queue.Queue(100)
         Thread(target=self._request_log_worker).start()
     
 
@@ -21,7 +21,7 @@
         now = datetime.now()
         time = now.strftime('%Y-%m-%d %H:%M:%S')
         td = (now - request.start_time)
-        duration = (td.microseconds + long(td.seconds + td.days*24*3600) * 1e6) / 1e6
+        duration = (td.microseconds + int(td.seconds + td.days*24*3600) * 1e6) / 1e6
         
         # write output including timestamp, status code, response time, response size, request action
         self.request_log_queue.put("'%s', '%s', '%s', '%s', '%s'\n" % (time, response.status, duration, len, request.params['Action']))
--- resultset.py	(original)
+++ resultset.py	(refactored)
@@ -145,7 +145,7 @@
         else:
             return 'False'
 
-    def __nonzero__(self):
+    def __bool__(self):
         return self.status
 
     def startElement(self, name, attrs, connection):
--- roboto/awsqueryrequest.py	(original)
+++ roboto/awsqueryrequest.py	(refactored)
@@ -47,10 +47,10 @@
             else:
                 debugger.post_mortem(tb)
         elif debug_flag:
-            print traceback.print_tb(tb)
-            sys.exit(1)
-        else:
-            print value
+            print(traceback.print_tb(tb))
+            sys.exit(1)
+        else:
+            print(value)
             sys.exit(1)
 
     return excepthook
@@ -69,7 +69,7 @@
 
     def print_it(self):
         if not self.printed:
-            print self.line
+            print(self.line)
             self.printed = True
 
 class RequiredParamError(boto.exception.BotoClientError):
@@ -342,9 +342,9 @@
 
     def process_standard_options(self, options, args, d):
         if hasattr(options, 'help_filters') and options.help_filters:
-            print 'Available filters:'
+            print('Available filters:')
             for filter in self.Filters:
-                print '%s\t%s' % (filter.name, filter.doc)
+                print('%s\t%s' % (filter.name, filter.doc))
             sys.exit(0)
         if options.debug:
             self.args['debug'] = 2
@@ -358,7 +358,7 @@
             self.args['aws_secret_access_key'] = options.secret_key
         if options.version:
             # TODO - Where should the version # come from?
-            print 'version x.xx'
+            print('version x.xx')
             exit(0)
         sys.excepthook = boto_except_hook(options.debugger,
                                           options.debug)
@@ -452,17 +452,17 @@
         try:
             response = self.main()
             self.cli_formatter(response)
-        except RequiredParamError, e:
-            print e
-            sys.exit(1)
-        except self.ServiceClass.ResponseError, err:
-            print 'Error(%s): %s' % (err.error_code, err.error_message)
-            sys.exit(1)
-        except boto.roboto.awsqueryservice.NoCredentialsError, err:
-            print 'Unable to find credentials.'
-            sys.exit(1)
-        except Exception, e:
-            print e
+        except RequiredParamError as e:
+            print(e)
+            sys.exit(1)
+        except self.ServiceClass.ResponseError as err:
+            print('Error(%s): %s' % (err.error_code, err.error_message))
+            sys.exit(1)
+        except boto.roboto.awsqueryservice.NoCredentialsError as err:
+            print('Unable to find credentials.')
+            sys.exit(1)
+        except Exception as e:
+            print(e)
             sys.exit(1)
 
     def _generic_cli_formatter(self, fmt, data, label=''):
@@ -483,7 +483,7 @@
                 if isinstance(item, dict):
                     for field_name in item:
                         line.append(item[field_name])
-                elif isinstance(item, basestring):
+                elif isinstance(item, str):
                     line.append(item)
                 line.print_it()
 
--- roboto/awsqueryservice.py	(original)
+++ roboto/awsqueryservice.py	(refactored)
@@ -1,10 +1,10 @@
 import os
-import urlparse
+import urllib.parse
 import boto
 import boto.connection
 import boto.jsonresponse
 import boto.exception
-import awsqueryrequest
+from . import awsqueryrequest
 
 class NoCredentialsError(boto.exception.BotoClientError):
 
@@ -77,7 +77,7 @@
                                     value = value.strip()
                                     self.args['aws_secret_access_key'] = value
             else:
-                print 'Warning: unable to read AWS_CREDENTIAL_FILE'
+                print('Warning: unable to read AWS_CREDENTIAL_FILE')
 
     def check_for_env_url(self):
         """
@@ -95,7 +95,7 @@
         if not url and self.EnvURL in os.environ:
             url = os.environ[self.EnvURL]
         if url:
-            rslt = urlparse.urlparse(url)
+            rslt = urllib.parse.urlparse(url)
             if 'is_secure' not in self.args:
                 if rslt.scheme == 'https':
                     self.args['is_secure'] = True
--- roboto/param.py	(original)
+++ roboto/param.py	(refactored)
@@ -27,7 +27,7 @@
     @classmethod
     def convert_string(cls, param, value):
         # TODO: could do length validation, etc. here
-        if not isinstance(value, basestring):
+        if not isinstance(value, str):
             raise ValueError
         return value
 
--- route53/connection.py	(original)
+++ route53/connection.py	(refactored)
@@ -24,9 +24,9 @@
 # IN THE SOFTWARE.
 #
 
-import exception
+from . import exception
 import random
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import uuid
 import xml.sax
 
@@ -79,10 +79,10 @@
     def make_request(self, action, path, headers=None, data='', params=None):
         if params:
             pairs = []
-            for key, val in params.iteritems():
+            for key, val in params.items():
                 if val is None:
                     continue
-                pairs.append(key + '=' + urllib.quote(str(val)))
+                pairs.append(key + '=' + urllib.parse.quote(str(val)))
             path += '?' + '&'.join(pairs)
         return super(Route53Connection, self).make_request(action, path,
                                               headers, data,
--- s3/bucket.py	(original)
+++ s3/bucket.py	(refactored)
@@ -45,8 +45,8 @@
 import boto.utils
 import xml.sax
 import xml.sax.saxutils
-import StringIO
-import urllib
+import io
+import urllib.request, urllib.parse, urllib.error
 import re
 import base64
 from collections import defaultdict
@@ -187,8 +187,8 @@
         if version_id:
             query_args_l.append('versionId=%s' % version_id)
         if response_headers:
-            for rk, rv in response_headers.iteritems():
-                query_args_l.append('%s=%s' % (rk, urllib.quote(rv)))
+            for rk, rv in response_headers.items():
+                query_args_l.append('%s=%s' % (rk, urllib.parse.quote(rv)))
 
         key, resp = self._get_key_internal(key_name, headers, query_args_l)
         return key
@@ -374,16 +374,16 @@
         if initial_query_string:
             pairs.append(initial_query_string)
 
-        for key, value in params.items():
+        for key, value in list(params.items()):
             key = key.replace('_', '-')
             if key == 'maxkeys':
                 key = 'max-keys'
-            if isinstance(value, unicode):
+            if isinstance(value, str):
                 value = value.encode('utf-8')
             if value is not None and value != '':
                 pairs.append('%s=%s' % (
-                    urllib.quote(key),
-                    urllib.quote(str(value)
+                    urllib.parse.quote(key),
+                    urllib.parse.quote(str(value)
                 )))
 
         return '&'.join(pairs)
@@ -663,17 +663,17 @@
 
         def delete_keys2(hdrs):
             hdrs = hdrs or {}
-            data = u"""<?xml version="1.0" encoding="UTF-8"?>"""
-            data += u"<Delete>"
+            data = """<?xml version="1.0" encoding="UTF-8"?>"""
+            data += "<Delete>"
             if quiet:
-                data += u"<Quiet>true</Quiet>"
+                data += "<Quiet>true</Quiet>"
             count = 0
             while count < 1000:
                 try:
-                    key = ikeys.next()
+                    key = next(ikeys)
                 except StopIteration:
                     break
-                if isinstance(key, basestring):
+                if isinstance(key, str):
                     key_name = key
                     version_id = None
                 elif isinstance(key, tuple) and len(key) == 2:
@@ -693,15 +693,15 @@
                     result.errors.append(error)
                     continue
                 count += 1
-                data += u"<Object><Key>%s</Key>" % xml.sax.saxutils.escape(key_name)
+                data += "<Object><Key>%s</Key>" % xml.sax.saxutils.escape(key_name)
                 if version_id:
-                    data += u"<VersionId>%s</VersionId>" % version_id
-                data += u"</Object>"
-            data += u"</Delete>"
+                    data += "<VersionId>%s</VersionId>" % version_id
+                data += "</Object>"
+            data += "</Delete>"
             if count <= 0:
                 return False  # no more
             data = data.encode('utf-8')
-            fp = StringIO.StringIO(data)
+            fp = io.StringIO(data)
             md5 = boto.utils.compute_md5(fp)
             hdrs['Content-MD5'] = md5[1]
             hdrs['Content-Type'] = 'text/xml'
@@ -851,7 +851,7 @@
             acl = src_bucket.get_xml_acl(src_key_name)
         if encrypt_key:
             headers[provider.server_side_encryption_header] = 'AES256'
-        src = '%s/%s' % (src_bucket_name, urllib.quote(src_key_name))
+        src = '%s/%s' % (src_bucket_name, urllib.parse.quote(src_key_name))
         if src_version_id:
             src += '?versionId=%s' % src_version_id
         headers[provider.copy_source_header] = str(src)
@@ -1327,7 +1327,7 @@
         """
         xml = lifecycle_config.to_xml()
         xml = xml.encode('utf-8')
-        fp = StringIO.StringIO(xml)
+        fp = io.StringIO(xml)
         md5 = boto.utils.compute_md5(fp)
         if headers is None:
             headers = {}
@@ -1591,7 +1591,7 @@
             CORS configuration.  See the S3 documentation for details
             of the exact syntax required.
         """
-        fp = StringIO.StringIO(cors_xml)
+        fp = io.StringIO(cors_xml)
         md5 = boto.utils.compute_md5(fp)
         if headers is None:
             headers = {}
@@ -1818,7 +1818,7 @@
     def set_xml_tags(self, tag_str, headers=None, query_args='tagging'):
         if headers is None:
             headers = {}
-        md5 = boto.utils.compute_md5(StringIO.StringIO(tag_str))
+        md5 = boto.utils.compute_md5(io.StringIO(tag_str))
         headers['Content-MD5'] = md5[1]
         headers['Content-Type'] = 'text/xml'
         response = self.connection.make_request('PUT', self.name,
--- s3/bucketlogging.py	(original)
+++ s3/bucketlogging.py	(refactored)
@@ -20,7 +20,7 @@
 # IN THE SOFTWARE.
 
 import xml.sax.saxutils
-from acl import Grant
+from .acl import Grant
 
 class BucketLogging(object):
 
@@ -66,18 +66,18 @@
 
     def to_xml(self):
         # caller is responsible to encode to utf-8
-        s = u'<?xml version="1.0" encoding="UTF-8"?>'
-        s += u'<BucketLoggingStatus xmlns="http://doc.s3.amazonaws.com/2006-03-01">'
+        s = '<?xml version="1.0" encoding="UTF-8"?>'
+        s += '<BucketLoggingStatus xmlns="http://doc.s3.amazonaws.com/2006-03-01">'
         if self.target is not None:
-            s += u'<LoggingEnabled>'
-            s += u'<TargetBucket>%s</TargetBucket>' % self.target
+            s += '<LoggingEnabled>'
+            s += '<TargetBucket>%s</TargetBucket>' % self.target
             prefix = self.prefix or ''
-            s += u'<TargetPrefix>%s</TargetPrefix>' % xml.sax.saxutils.escape(prefix)
+            s += '<TargetPrefix>%s</TargetPrefix>' % xml.sax.saxutils.escape(prefix)
             if self.grants:
                 s += '<TargetGrants>'
                 for grant in self.grants:
                     s += grant.to_xml()
                 s += '</TargetGrants>'
-            s += u'</LoggingEnabled>'
-        s += u'</BucketLoggingStatus>'
+            s += '</LoggingEnabled>'
+        s += '</BucketLoggingStatus>'
         return s
--- s3/connection.py	(original)
+++ s3/connection.py	(refactored)
@@ -23,7 +23,7 @@
 # IN THE SOFTWARE.
 
 import xml.sax
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import base64
 import time
 
@@ -92,11 +92,11 @@
         path = ''
         if bucket != '':
             path = '/' + bucket
-        return path + '/%s' % urllib.quote(key)
+        return path + '/%s' % urllib.parse.quote(key)
 
     def build_path_base(self, bucket, key=''):
         key = boto.utils.get_utf8_value(key)
-        return '/%s' % urllib.quote(key)
+        return '/%s' % urllib.parse.quote(key)
 
 
 class SubdomainCallingFormat(_CallingFormat):
@@ -123,7 +123,7 @@
         path_base = '/'
         if bucket:
             path_base += "%s/" % bucket
-        return path_base + urllib.quote(key)
+        return path_base + urllib.parse.quote(key)
 
 
 class ProtocolIndependentOrdinaryCallingFormat(OrdinaryCallingFormat):
@@ -176,7 +176,7 @@
         if host is NoHostProvided:
             no_host_provided = True
             host = self.DefaultHost
-        if isinstance(calling_format, basestring):
+        if isinstance(calling_format, str):
             calling_format=boto.utils.find_class(calling_format)()
         self.calling_format = calling_format
         self.bucket_class = bucket_class
@@ -366,8 +366,8 @@
         if version_id is not None:
             extra_qp.append("versionId=%s" % version_id)
         if response_headers:
-            for k, v in response_headers.items():
-                extra_qp.append("%s=%s" % (k, urllib.quote(v)))
+            for k, v in list(response_headers.items()):
+                extra_qp.append("%s=%s" % (k, urllib.parse.quote(v)))
         if self.provider.security_token:
             headers['x-amz-security-token'] = self.provider.security_token
         if extra_qp:
@@ -376,7 +376,7 @@
         c_string = boto.utils.canonical_string(method, auth_path, headers,
                                                expires, self.provider)
         b64_hmac = self._auth_handler.sign_string(c_string)
-        encoded_canonical = urllib.quote(b64_hmac, safe='')
+        encoded_canonical = urllib.parse.quote(b64_hmac, safe='')
         self.calling_format.build_path_base(bucket, key)
         if query_auth:
             query_part = '?' + self.QueryString % (encoded_canonical, expires,
@@ -385,11 +385,11 @@
             query_part = ''
         if headers:
             hdr_prefix = self.provider.header_prefix
-            for k, v in headers.items():
+            for k, v in list(headers.items()):
                 if k.startswith(hdr_prefix):
                     # headers used for sig generation must be
                     # included in the url also.
-                    extra_qp.append("%s=%s" % (k, urllib.quote(v)))
+                    extra_qp.append("%s=%s" % (k, urllib.parse.quote(v)))
         if extra_qp:
             delimiter = '?' if not query_part else '&'
             query_part += delimiter + '&'.join(extra_qp)
--- s3/key.py	(original)
+++ s3/key.py	(refactored)
@@ -21,18 +21,18 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-from __future__ import with_statement
+
 import errno
 import hashlib
 import mimetypes
 import os
 import re
 import rfc822
-import StringIO
+import io
 import base64
 import binascii
 import math
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import boto.utils
 from boto.exception import BotoClientError
 from boto.exception import StorageDataError
@@ -274,7 +274,7 @@
             response_headers = self.resp.msg
             self.metadata = boto.utils.get_aws_metadata(response_headers,
                                                         provider)
-            for name, value in response_headers.items():
+            for name, value in list(response_headers.items()):
                 # To get correct size for Range GETs, use Content-Range
                 # header if one was returned. If not, use Content-Length
                 # header.
@@ -354,7 +354,7 @@
         self.mode = None
         self.closed = True
 
-    def next(self):
+    def __next__(self):
         """
         By providing a next method, the key object supports use as an iterator.
         For example, you can now say:
@@ -1371,9 +1371,9 @@
             be encrypted on the server-side by S3 and will be stored
             in an encrypted form while at rest in S3.
         """
-        if isinstance(string_data, unicode):
+        if isinstance(string_data, str):
             string_data = string_data.encode("utf-8")
-        fp = StringIO.StringIO(string_data)
+        fp = io.StringIO(string_data)
         r = self.set_contents_from_file(fp, headers, replace, cb, num_cb,
                                         policy, md5, reduced_redundancy,
                                         encrypt_key=encrypt_key)
@@ -1461,7 +1461,7 @@
         if response_headers:
             for key in response_headers:
                 query_args.append('%s=%s' % (
-                    key, urllib.quote(response_headers[key])))
+                    key, urllib.parse.quote(response_headers[key])))
         query_args = '&'.join(query_args)
         self.open('r', headers, query_args=query_args,
                   override_num_retries=override_num_retries)
@@ -1497,7 +1497,7 @@
                     if i == cb_count or cb_count == -1:
                         cb(data_len, cb_size)
                         i = 0
-        except IOError, e:
+        except IOError as e:
             if e.errno == errno.ENOSPC:
                 raise StorageDataError('Out of space for destination file '
                                        '%s' % fp.name)
@@ -1724,7 +1724,7 @@
         :rtype: string
         :returns: The contents of the file as a string
         """
-        fp = StringIO.StringIO()
+        fp = io.StringIO()
         self.get_contents_to_file(fp, headers, cb, num_cb, torrent=torrent,
                                   version_id=version_id,
                                   response_headers=response_headers)
--- s3/keyfile.py	(original)
+++ s3/keyfile.py	(refactored)
@@ -75,7 +75,7 @@
       raise IOError('Invalid whence param (%d) passed to seek' % whence)
     try:
       self.key.open_read(headers={"Range": "bytes=%d-" % pos})
-    except StorageResponseError, e:
+    except StorageResponseError as e:
       # 416 Invalid Range means that the given starting byte was past the end
       # of file. We catch this because the Python file interface allows silently
       # seeking past the end of the file.
@@ -112,7 +112,7 @@
   def flush(self):
     raise NotImplementedError('flush not implemented in KeyFile')
 
-  def next(self):
+  def __next__(self):
     raise NotImplementedError('next not implemented in KeyFile')
 
   def readinto(self):
--- s3/lifecycle.py	(original)
+++ s3/lifecycle.py	(refactored)
@@ -48,7 +48,7 @@
         self.id = id
         self.prefix = '' if prefix is None else prefix
         self.status = status
-        if isinstance(expiration, (int, long)):
+        if isinstance(expiration, int):
             # retain backwards compatibility???
             self.expiration = Expiration(days=expiration)
         else:
--- s3/multipart.py	(original)
+++ s3/multipart.py	(refactored)
@@ -22,8 +22,8 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-import user
-import key
+from . import user
+from . import key
 from boto import handler
 import xml.sax
 
--- s3/resumable_download_handler.py	(original)
+++ s3/resumable_download_handler.py	(refactored)
@@ -20,7 +20,7 @@
 # IN THE SOFTWARE.
 
 import errno
-import httplib
+import http.client
 import os
 import re
 import socket
@@ -93,7 +93,7 @@
 
     MIN_ETAG_LEN = 5
 
-    RETRYABLE_EXCEPTIONS = (httplib.HTTPException, IOError, socket.error,
+    RETRYABLE_EXCEPTIONS = (http.client.HTTPException, IOError, socket.error,
                             socket.gaierror)
 
     def __init__(self, tracker_file_name=None, num_retries=None):
@@ -133,17 +133,17 @@
             # read correctly. Since ETags need not be MD5s, we now do a simple
             # length sanity check instead.
             if len(self.etag_value_for_current_download) < self.MIN_ETAG_LEN:
-                print('Couldn\'t read etag in tracker file (%s). Restarting '
-                      'download from scratch.' % self.tracker_file_name)
-        except IOError, e:
+                print(('Couldn\'t read etag in tracker file (%s). Restarting '
+                      'download from scratch.' % self.tracker_file_name))
+        except IOError as e:
             # Ignore non-existent file (happens first time a download
             # is attempted on an object), but warn user for other errors.
             if e.errno != errno.ENOENT:
                 # Will restart because
                 # self.etag_value_for_current_download is None.
-                print('Couldn\'t read URI tracker file (%s): %s. Restarting '
+                print(('Couldn\'t read URI tracker file (%s): %s. Restarting '
                       'download from scratch.' %
-                      (self.tracker_file_name, e.strerror))
+                      (self.tracker_file_name, e.strerror)))
         finally:
             if f:
                 f.close()
@@ -156,7 +156,7 @@
         try:
             f = open(self.tracker_file_name, 'w')
             f.write('%s\n' % self.etag_value_for_current_download)
-        except IOError, e:
+        except IOError as e:
             raise ResumableDownloadException(
                 'Couldn\'t write tracker file (%s): %s.\nThis can happen'
                 'if you\'re using an incorrectly configured download tool\n'
@@ -194,17 +194,17 @@
                    key.size), ResumableTransferDisposition.ABORT)
             elif cur_file_size == key.size:
                 if key.bucket.connection.debug >= 1:
-                    print 'Download complete.'
+                    print('Download complete.')
                 return
             if key.bucket.connection.debug >= 1:
-                print 'Resuming download.'
+                print('Resuming download.')
             headers = headers.copy()
             headers['Range'] = 'bytes=%d-%d' % (cur_file_size, key.size - 1)
             cb = ByteTranslatingCallbackHandler(cb, cur_file_size).call
             self.download_start_point = cur_file_size
         else:
             if key.bucket.connection.debug >= 1:
-                print 'Starting new resumable download.'
+                print('Starting new resumable download.')
             self._save_tracker_info(key)
             self.download_start_point = 0
             # Truncate the file, in case a new resumable download is being
@@ -285,11 +285,11 @@
                 # non-resumable downloads, this call was removed. Checksum
                 # validation of file contents should be done by the caller.
                 if debug >= 1:
-                    print 'Resumable download complete.'
+                    print('Resumable download complete.')
                 return
-            except self.RETRYABLE_EXCEPTIONS, e:
+            except self.RETRYABLE_EXCEPTIONS as e:
                 if debug >= 1:
-                    print('Caught exception (%s)' % e.__repr__())
+                    print(('Caught exception (%s)' % e.__repr__()))
                 if isinstance(e, IOError) and e.errno == errno.EPIPE:
                     # Broken pipe error causes httplib to immediately
                     # close the socket (http://bugs.python.org/issue5542),
@@ -301,25 +301,25 @@
                     else:
                       key.get_file(fp, headers, cb, num_cb, torrent, version_id,
                                    override_num_retries=0)
-            except ResumableDownloadException, e:
+            except ResumableDownloadException as e:
                 if (e.disposition ==
                     ResumableTransferDisposition.ABORT_CUR_PROCESS):
                     if debug >= 1:
-                        print('Caught non-retryable ResumableDownloadException '
-                              '(%s)' % e.message)
+                        print(('Caught non-retryable ResumableDownloadException '
+                              '(%s)' % e.message))
                     raise
                 elif (e.disposition ==
                     ResumableTransferDisposition.ABORT):
                     if debug >= 1:
-                        print('Caught non-retryable ResumableDownloadException '
+                        print(('Caught non-retryable ResumableDownloadException '
                               '(%s); aborting and removing tracker file' %
-                              e.message)
+                              e.message))
                     self._remove_tracker_file()
                     raise
                 else:
                     if debug >= 1:
-                        print('Caught ResumableDownloadException (%s) - will '
-                              'retry' % e.message)
+                        print(('Caught ResumableDownloadException (%s) - will '
+                              'retry' % e.message))
 
             # At this point we had a re-tryable failure; see if made progress.
             if get_cur_file_size(fp) > had_file_bytes_before_attempt:
@@ -342,12 +342,12 @@
             # which we can safely ignore.
             try:
                 key.close()
-            except httplib.IncompleteRead:
+            except http.client.IncompleteRead:
                 pass
 
             sleep_time_secs = 2**progress_less_iterations
             if debug >= 1:
-                print('Got retryable failure (%d progress-less in a row).\n'
+                print(('Got retryable failure (%d progress-less in a row).\n'
                       'Sleeping %d seconds before re-trying' %
-                      (progress_less_iterations, sleep_time_secs))
+                      (progress_less_iterations, sleep_time_secs)))
             time.sleep(sleep_time_secs)
--- sdb/connection.py	(original)
+++ sdb/connection.py	(refactored)
@@ -174,14 +174,14 @@
             params['Expected.1.Value'] = expected_value[1]
 
     def _build_batch_list(self, params, items, replace=False):
-        item_names = items.keys()
+        item_names = list(items.keys())
         i = 0
         for item_name in item_names:
             params['Item.%d.ItemName' % i] = item_name
             j = 0
             item = items[item_name]
             if item is not None:
-                attr_names = item.keys()
+                attr_names = list(item.keys())
                 for attr_name in attr_names:
                     value = item[attr_name]
                     if isinstance(value, list):
@@ -235,9 +235,9 @@
             requests made on this specific connection instance. It is by
             no means an account-wide estimate.
         """
-        print 'Total Usage: %f compute seconds' % self.box_usage
+        print('Total Usage: %f compute seconds' % self.box_usage)
         cost = self.box_usage * 0.14
-        print 'Approximate Cost: $%f' % cost
+        print('Approximate Cost: $%f' % cost)
 
     def get_domain(self, domain_name, validate=True):
         """
@@ -614,6 +614,6 @@
         try:
             return self.get_list('Select', params, [('Item', self.item_cls)],
                              parent=domain)
-        except SDBResponseError, e:
+        except SDBResponseError as e:
             e.body = "Query: %s\n%s" % (query, e.body)
             raise e
--- sdb/domain.py	(original)
+++ sdb/domain.py	(refactored)
@@ -240,26 +240,26 @@
         if not f:
             from tempfile import TemporaryFile
             f = TemporaryFile()
-        print >> f, '<?xml version="1.0" encoding="UTF-8"?>'
-        print >> f, '<Domain id="%s">' % self.name
+        print('<?xml version="1.0" encoding="UTF-8"?>', file=f)
+        print('<Domain id="%s">' % self.name, file=f)
         for item in self:
-            print >> f, '\t<Item id="%s">' % item.name
+            print('\t<Item id="%s">' % item.name, file=f)
             for k in item:
-                print >> f, '\t\t<attribute id="%s">' % k
+                print('\t\t<attribute id="%s">' % k, file=f)
                 values = item[k]
                 if not isinstance(values, list):
                     values = [values]
                 for value in values:
-                    print >> f, '\t\t\t<value><![CDATA[',
-                    if isinstance(value, unicode):
+                    print('\t\t\t<value><![CDATA[', end=' ', file=f)
+                    if isinstance(value, str):
                         value = value.encode('utf-8', 'replace')
                     else:
-                        value = unicode(value, errors='replace').encode('utf-8', 'replace')
+                        value = str(value, errors='replace').encode('utf-8', 'replace')
                     f.write(value)
-                    print >> f, ']]></value>'
-                print >> f, '\t\t</attribute>'
-            print >> f, '\t</Item>'
-        print >> f, '</Domain>'
+                    print(']]></value>', file=f)
+                print('\t\t</attribute>', file=f)
+            print('\t</Item>', file=f)
+        print('</Domain>', file=f)
         f.flush()
         f.seek(0)
         return f
@@ -370,8 +370,8 @@
         try:
             self.db.batch_put_attributes(self.items)
         except:
-            print "Exception using batch put, trying regular put instead"
+            print("Exception using batch put, trying regular put instead")
             for item_name in self.items:
                 self.db.put_attributes(item_name, self.items[item_name])
-        print ".",
+        print(".", end=' ')
         sys.stdout.flush()
--- sdb/queryresultset.py	(original)
+++ sdb/queryresultset.py	(refactored)
@@ -88,5 +88,5 @@
                 raise StopIteration
             more_results = self.next_token is not None
 
-    def next(self):
-        return self.__iter__().next()
+    def __next__(self):
+        return next(self.__iter__())
--- sdb/db/blob.py	(original)
+++ sdb/db/blob.py	(refactored)
@@ -29,7 +29,7 @@
 
     @property
     def file(self):
-        from StringIO import StringIO
+        from io import StringIO
         if self._file:
             f = self._file
         else:
@@ -37,14 +37,14 @@
         return f
 
     def __str__(self):
-        return unicode(self).encode('utf-8')
+        return str(self).encode('utf-8')
 
     def __unicode__(self):
         if hasattr(self.file, "get_contents_as_string"):
             value = self.file.get_contents_as_string()
         else:
             value = self.file.getvalue()
-        if isinstance(value, unicode):
+        if isinstance(value, str):
             return value
         else:
             return value.decode('utf-8')
@@ -59,8 +59,8 @@
     def readline(self):
         return self.file.readline()
 
-    def next(self):
-        return self.file.next()
+    def __next__(self):
+        return next(self.file)
 
     def __iter__(self):
         return iter(self.file)
--- sdb/db/model.py	(original)
+++ sdb/db/model.py	(refactored)
@@ -36,12 +36,12 @@
         from boto.sdb.db.manager import get_manager
 
         try:
-            if filter(lambda b: issubclass(b, Model), bases):
+            if [b for b in bases if issubclass(b, Model)]:
                 for base in bases:
                     base.__sub_classes__.append(cls)
                 cls._manager = get_manager(cls)
                 # look for all of the Properties and set their names
-                for key in dict.keys():
+                for key in list(dict.keys()):
                     if isinstance(dict[key], Property):
                         property = dict[key]
                         property.__property_config__(cls, key)
@@ -56,8 +56,7 @@
             # Model class, defined below.
             pass
 
-class Model(object):
-    __metaclass__ = ModelMeta
+class Model(object, metaclass=ModelMeta):
     __consistent__ = False # Consistent is set off by default
     id = None
 
@@ -94,7 +93,7 @@
     @classmethod
     def find(cls, limit=None, next_token=None, **params):
         q = Query(cls, limit=limit, next_token=next_token)
-        for key, value in params.items():
+        for key, value in list(params.items()):
             q.filter('%s =' % key, value)
         return q
 
@@ -110,7 +109,7 @@
     def properties(cls, hidden=True):
         properties = []
         while cls:
-            for key in cls.__dict__.keys():
+            for key in list(cls.__dict__.keys()):
                 prop = cls.__dict__[key]
                 if isinstance(prop, Property):
                     if hidden or not prop.__class__.__name__.startswith('_'):
@@ -125,7 +124,7 @@
     def find_property(cls, prop_name):
         property = None
         while cls:
-            for key in cls.__dict__.keys():
+            for key in list(cls.__dict__.keys()):
                 prop = cls.__dict__[key]
                 if isinstance(prop, Property):
                     if not prop.__class__.__name__.startswith('_') and prop_name == prop.name:
@@ -166,7 +165,7 @@
                 # so if it fails we just revert to it's default value
                 try:
                     setattr(self, key, kw[key])
-                except Exception, e:
+                except Exception as e:
                     boto.log.exception(e)
 
     def __repr__(self):
--- sdb/db/property.py	(original)
+++ sdb/db/property.py	(refactored)
@@ -20,13 +20,14 @@
 # IN THE SOFTWARE.
 
 import datetime
-from key import Key
+from .key import Key
 from boto.utils import Password
 from boto.sdb.db.query import Query
 import re
 import boto
 import boto.s3.key
 from boto.sdb.db.blob import Blob
+import collections
 
 
 class Property(object):
@@ -76,7 +77,7 @@
         self.slot_name = '_' + self.name
 
     def default_validator(self, value):
-        if isinstance(value, basestring) or value == self.default_value():
+        if isinstance(value, str) or value == self.default_value():
             return
         if not isinstance(value, self.data_type):
             raise TypeError('Validation Error, %s.%s expecting %s, got %s' % (self.model_class.__name__, self.name, self.data_type, type(value)))
@@ -105,7 +106,7 @@
         return value
 
     def get_choices(self):
-        if callable(self.choices):
+        if isinstance(self.choices, collections.Callable):
             return self.choices()
         return self.choices
 
@@ -113,7 +114,7 @@
 def validate_string(value):
     if value is None:
         return
-    elif isinstance(value, basestring):
+    elif isinstance(value, str):
         if len(value) > 1024:
             raise ValueError('Length of value greater than maxlength')
     else:
@@ -144,7 +145,7 @@
 
     def validate(self, value):
         value = super(TextProperty, self).validate(value)
-        if not isinstance(value, basestring):
+        if not isinstance(value, str):
             raise TypeError('Expecting Text, got %s' % type(value))
         if self.max_length and len(value) > self.max_length:
             raise ValueError('Length of value greater than maxlength %s' % self.max_length)
@@ -335,7 +336,7 @@
 
 class LongProperty(Property):
 
-    data_type = long
+    data_type = int
     type_name = 'Long'
 
     def __init__(self, verbose_name=None, name=None, default=0, required=False,
@@ -343,7 +344,7 @@
         super(LongProperty, self).__init__(verbose_name, name, default, required, validator, choices, unique)
 
     def validate(self, value):
-        value = long(value)
+        value = int(value)
         value = super(LongProperty, self).validate(value)
         min = -9223372036854775808
         max = 9223372036854775807
@@ -493,7 +494,7 @@
             # If the value is still the UUID for the referenced object, we need to create
             # the object now that is the attribute has actually been accessed.  This lazy
             # instantiation saves unnecessary roundtrips to SimpleDB
-            if isinstance(value, basestring):
+            if isinstance(value, str):
                 value = self.reference_class(value)
                 setattr(obj, self.name, value)
             return value
@@ -537,7 +538,7 @@
             raise ValueError('%s is a required property' % self.name)
         if value == self.default_value():
             return
-        if not isinstance(value, basestring):
+        if not isinstance(value, str):
             self.check_instance(value)
 
 
@@ -626,16 +627,16 @@
             if not isinstance(value, list):
                 value = [value]
 
-        if self.item_type in (int, long):
-            item_type = (int, long)
-        elif self.item_type in (str, unicode):
-            item_type = (str, unicode)
+        if self.item_type in (int, int):
+            item_type = (int, int)
+        elif self.item_type in (str, str):
+            item_type = (str, str)
         else:
             item_type = self.item_type
 
         for item in value:
             if not isinstance(item, item_type):
-                if item_type == (int, long):
+                if item_type == (int, int):
                     raise ValueError('Items in the %s list must all be integers.' % self.name)
                 else:
                     raise ValueError('Items in the %s list must all be %s instances' %
@@ -650,10 +651,10 @@
 
     def __set__(self, obj, value):
         """Override the set method to allow them to set the property to an instance of the item_type instead of requiring a list to be passed in"""
-        if self.item_type in (int, long):
-            item_type = (int, long)
-        elif self.item_type in (str, unicode):
-            item_type = (str, unicode)
+        if self.item_type in (int, int):
+            item_type = (int, int)
+        elif self.item_type in (str, str):
+            item_type = (str, str)
         else:
             item_type = self.item_type
         if isinstance(value, item_type):
@@ -680,16 +681,16 @@
             if not isinstance(value, dict):
                 raise ValueError('Value must of type dict')
 
-        if self.item_type in (int, long):
-            item_type = (int, long)
-        elif self.item_type in (str, unicode):
-            item_type = (str, unicode)
+        if self.item_type in (int, int):
+            item_type = (int, int)
+        elif self.item_type in (str, str):
+            item_type = (str, str)
         else:
             item_type = self.item_type
 
         for key in value:
             if not isinstance(value[key], item_type):
-                if item_type == (int, long):
+                if item_type == (int, int):
                     raise ValueError('Values in the %s Map must all be integers.' % self.name)
                 else:
                     raise ValueError('Values in the %s Map must all be %s instances' %
--- sdb/db/query.py	(original)
+++ sdb/db/query.py	(refactored)
@@ -38,10 +38,10 @@
     def __iter__(self):
         return iter(self.manager.query(self))
 
-    def next(self):
+    def __next__(self):
         if self.__local_iter__ is None:
             self.__local_iter__ = self.__iter__()
-        return self.__local_iter__.next()
+        return next(self.__local_iter__)
 
     def filter(self, property_operator, value):
         self.filters.append((property_operator, value))
--- sdb/db/sequence.py	(original)
+++ sdb/db/sequence.py	(refactored)
@@ -146,7 +146,7 @@
         self.item_type = type(fnc(None))
         self.timestamp = None
         # Allow us to pass in a full name to a function
-        if isinstance(fnc, basestring):
+        if isinstance(fnc, str):
             from boto.utils import find_class
             fnc = find_class(fnc)
         self.fnc = fnc
@@ -169,7 +169,7 @@
         try:
             self.db.put_attributes(self.id, new_val, expected_value=expected_value)
             self.timestamp = new_val['timestamp']
-        except SDBResponseError, e:
+        except SDBResponseError as e:
             if e.status == 409:
                 raise ValueError("Sequence out of sync")
             else:
@@ -208,7 +208,7 @@
                 self.domain_name = boto.config.get("DB", "sequence_db", boto.config.get("DB", "db_name", "default"))
             try:
                 self._db = sdb.get_domain(self.domain_name)
-            except SDBResponseError, e:
+            except SDBResponseError as e:
                 if e.status == 400:
                     self._db = sdb.create_domain(self.domain_name)
                 else:
@@ -217,7 +217,7 @@
 
     db = property(_connect)
 
-    def next(self):
+    def __next__(self):
         self.val = self.fnc(self.val, self.last_value)
         return self.val
 
--- sdb/db/manager/sdbmanager.py	(original)
+++ sdb/db/manager/sdbmanager.py	(refactored)
@@ -58,7 +58,7 @@
         self.manager = manager
         self.type_map = {bool: (self.encode_bool, self.decode_bool),
                          int: (self.encode_int, self.decode_int),
-                         long: (self.encode_long, self.decode_long),
+                         int: (self.encode_long, self.decode_long),
                          float: (self.encode_float, self.decode_float),
                          self.model_class: (
                             self.encode_reference, self.decode_reference
@@ -106,7 +106,7 @@
         return self.encode_map(prop, values)
 
     def encode_map(self, prop, value):
-        import urllib
+        import urllib.request, urllib.parse, urllib.error
         if value is None:
             return None
         if not isinstance(value, dict):
@@ -118,7 +118,7 @@
                 item_type = self.model_class
             encoded_value = self.encode(item_type, value[key])
             if encoded_value is not None:
-                new_value.append('%s:%s' % (urllib.quote(key), encoded_value))
+                new_value.append('%s:%s' % (urllib.parse.quote(key), encoded_value))
         return new_value
 
     def encode_prop(self, prop, value):
@@ -143,7 +143,7 @@
                     except:
                         k = v
                     dec_val[k] = v
-            value = dec_val.values()
+            value = list(dec_val.values())
         return value
 
     def decode_map(self, prop, value):
@@ -158,11 +158,11 @@
 
     def decode_map_element(self, item_type, value):
         """Decode a single element for a map"""
-        import urllib
+        import urllib.request, urllib.parse, urllib.error
         key = value
         if ":" in value:
             key, value = value.split(':', 1)
-            key = urllib.unquote(key)
+            key = urllib.parse.unquote(key)
         if self.model_class in item_type.mro():
             value = item_type(id=value)
         else:
@@ -193,12 +193,12 @@
         return int(value)
 
     def encode_long(self, value):
-        value = long(value)
+        value = int(value)
         value += 9223372036854775808
         return '%020d' % value
 
     def decode_long(self, value):
-        value = long(value)
+        value = int(value)
         value -= 9223372036854775808
         return value
 
@@ -264,7 +264,7 @@
         return float(mantissa + 'e' + exponent)
 
     def encode_datetime(self, value):
-        if isinstance(value, basestring):
+        if isinstance(value, str):
             return value
         if isinstance(value, datetime):
             return value.strftime(ISO8601)
@@ -285,11 +285,11 @@
             else:
                 value = value.split("-")
                 return date(int(value[0]), int(value[1]), int(value[2]))
-        except Exception, e:
+        except Exception as e:
             return None
 
     def encode_date(self, value):
-        if isinstance(value, basestring):
+        if isinstance(value, str):
             return value
         return value.isoformat()
 
@@ -314,7 +314,7 @@
             # TODO: Handle tzinfo
             raise TimeDecodeError("Can't handle timezone aware objects: %r" % value)
         tmp = value.split('.')
-        arg = map(int, tmp[0].split(':'))
+        arg = list(map(int, tmp[0].split(':')))
         if len(tmp) == 2:
             arg.append(int(tmp[1]))
         return time(*arg)
@@ -322,7 +322,7 @@
     def encode_reference(self, value):
         if value in (None, 'None', '', ' '):
             return None
-        if isinstance(value, basestring):
+        if isinstance(value, str):
             return value
         else:
             return value.id
@@ -335,7 +335,7 @@
     def encode_blob(self, value):
         if not value:
             return None
-        if isinstance(value, basestring):
+        if isinstance(value, str):
             return value
 
         if not value.id:
@@ -364,7 +364,7 @@
             bucket = s3.get_bucket(match.group(1), validate=False)
             try:
                 key = bucket.get_key(match.group(2))
-            except S3ResponseError, e:
+            except S3ResponseError as e:
                 if e.reason != "Forbidden":
                     raise
                 return None
@@ -380,15 +380,15 @@
         if not isinstance(value, str):
             return value
         try:
-            return unicode(value, 'utf-8')
+            return str(value, 'utf-8')
         except:
             # really, this should throw an exception.
             # in the interest of not breaking current
             # systems, however:
             arr = []
             for ch in value:
-                arr.append(unichr(ord(ch)))
-            return u"".join(arr)
+                arr.append(chr(ord(ch)))
+            return "".join(arr)
 
     def decode_string(self, value):
         """Decoding a string is really nothing, just
@@ -490,7 +490,7 @@
                         value = prop.make_value_from_datastore(value)
                         try:
                             setattr(obj, prop.name, value)
-                        except Exception, e:
+                        except Exception as e:
                             boto.log.exception(e)
             obj._loaded = True
 
@@ -581,7 +581,7 @@
                 order_by_filtered = True
             query_parts.append("(%s)" % select)
 
-        if isinstance(filters, basestring):
+        if isinstance(filters, str):
             query = "WHERE %s AND `__type__` = '%s'" % (filters, cls.__name__)
             if order_by in ["__id__", "itemName()"]:
                 query += " ORDER BY itemName() %s" % order_by_method
@@ -600,7 +600,7 @@
                 property = cls.find_property(name)
                 if name == order_by:
                     order_by_filtered = True
-                if types.TypeType(value) == types.ListType:
+                if types.TypeType(value) == list:
                     filter_parts_sub = []
                     for val in value:
                         val = self.encode_value(property, val)
@@ -621,7 +621,7 @@
 
 
         type_query = "(`__type__` = '%s'" % cls.__name__
-        for subclass in self._get_all_decendents(cls).keys():
+        for subclass in list(self._get_all_decendents(cls).keys()):
             type_query += " or `__type__` = '%s'" % subclass
         type_query += ")"
         query_parts.append(type_query)
@@ -674,7 +674,7 @@
             if property.unique:
                 try:
                     args = {property.name: value}
-                    obj2 = obj.find(**args).next()
+                    obj2 = next(obj.find(**args))
                     if obj2.id != obj.id:
                         raise SDBPersistenceError("Error: %s must be unique!" % property.name)
                 except(StopIteration):
@@ -701,7 +701,7 @@
         if prop.unique:
             try:
                 args = {prop.name: value}
-                obj2 = obj.find(**args).next()
+                obj2 = next(obj.find(**args))
                 if obj2.id != obj.id:
                     raise SDBPersistenceError("Error: %s must be unique!" % prop.name)
             except(StopIteration):
--- sdb/db/manager/xmlmanager.py	(original)
+++ sdb/db/manager/xmlmanager.py	(refactored)
@@ -43,7 +43,7 @@
         self.manager = manager
         self.type_map = { bool : (self.encode_bool, self.decode_bool),
                           int : (self.encode_int, self.decode_int),
-                          long : (self.encode_long, self.decode_long),
+                          int : (self.encode_long, self.decode_long),
                           Model : (self.encode_reference, self.decode_reference),
                           Key : (self.encode_reference, self.decode_reference),
                           Password : (self.encode_password, self.decode_password),
@@ -114,12 +114,12 @@
         return value
 
     def encode_long(self, value):
-        value = long(value)
+        value = int(value)
         return '%d' % value
 
     def decode_long(self, value):
         value = self.get_text_value(value)
-        return long(value)
+        return int(value)
 
     def encode_bool(self, value):
         if value == True:
@@ -145,7 +145,7 @@
             return None
 
     def encode_reference(self, value):
-        if isinstance(value, basestring):
+        if isinstance(value, str):
             return value
         if value is None:
             return ''
@@ -209,9 +209,9 @@
     def _connect(self):
         if self.db_host:
             if self.enable_ssl:
-                from httplib import HTTPSConnection as Connection
+                from http.client import HTTPSConnection as Connection
             else:
-                from httplib import HTTPConnection as Connection
+                from http.client import HTTPConnection as Connection
 
             self.connection = Connection(self.db_host, self.db_port)
 
@@ -347,7 +347,7 @@
         if not self.connection:
             raise NotImplementedError("Can't query without a database connection")
 
-        from urllib import urlencode
+        from urllib.parse import urlencode
 
         query = str(self._build_query(cls, filters, limit, order_by))
         if query:
@@ -373,7 +373,7 @@
             for property in properties:
                 if property.name == name:
                     found = True
-                    if types.TypeType(value) == types.ListType:
+                    if types.TypeType(value) == list:
                         filter_parts = []
                         for val in value:
                             val = self.encode_value(property, val)
@@ -459,14 +459,14 @@
                 elif isinstance(value, Node):
                     prop_node.appendChild(value)
                 else:
-                    text_node = doc.createTextNode(unicode(value).encode("ascii", "ignore"))
+                    text_node = doc.createTextNode(str(value).encode("ascii", "ignore"))
                     prop_node.appendChild(text_node)
             obj_node.appendChild(prop_node)
 
         return doc
 
     def unmarshal_object(self, fp, cls=None, id=None):
-        if isinstance(fp, basestring):
+        if isinstance(fp, str):
             doc = parseString(fp)
         else:
             doc = parse(fp)
@@ -477,7 +477,7 @@
         Same as unmarshalling an object, except it returns
         from "get_props_from_doc"
         """
-        if isinstance(fp, basestring):
+        if isinstance(fp, str):
             doc = parseString(fp)
         else:
             doc = parse(fp)
--- services/bs.py	(original)
+++ services/bs.py	(refactored)
@@ -24,7 +24,7 @@
 from boto.services.submit import Submitter
 from boto.services.result import ResultProcessor
 import boto
-import sys, os, StringIO
+import sys, os, io
 
 class BS(object):
 
@@ -62,32 +62,32 @@
                                help="batch identifier required by the retrieve command")
 
     def print_command_help(self):
-        print '\nCommands:'
-        for key in self.Commands.keys():
-            print '  %s\t\t%s' % (key, self.Commands[key])
+        print('\nCommands:')
+        for key in list(self.Commands.keys()):
+            print('  %s\t\t%s' % (key, self.Commands[key]))
 
     def do_reset(self):
         iq = self.sd.get_obj('input_queue')
         if iq:
-            print 'clearing out input queue'
+            print('clearing out input queue')
             i = 0
             m = iq.read()
             while m:
                 i += 1
                 iq.delete_message(m)
                 m = iq.read()
-            print 'deleted %d messages' % i
+            print('deleted %d messages' % i)
         ob = self.sd.get_obj('output_bucket')
         ib = self.sd.get_obj('input_bucket')
         if ob:
             if ib and ob.name == ib.name:
                 return
-            print 'delete generated files in output bucket'
+            print('delete generated files in output bucket')
             i = 0
             for k in ob:
                 i += 1
                 k.delete()
-            print 'deleted %d keys' % i
+            print('deleted %d keys' % i)
 
     def do_submit(self):
         if not self.options.path:
@@ -97,8 +97,8 @@
         s = Submitter(self.sd)
         t = s.submit_path(self.options.path, None, self.options.ignore, None,
                           None, True, self.options.path)
-        print 'A total of %d files were submitted' % t[1]
-        print 'Batch Identifier: %s' % t[0]
+        print('A total of %d files were submitted' % t[1])
+        print('Batch Identifier: %s' % t[0])
 
     def do_start(self):
         ami_id = self.sd.get('ami_id')
@@ -111,7 +111,7 @@
             self.sd.add_section('Credentials')
             self.sd.set('Credentials', 'aws_access_key_id', ec2.aws_access_key_id)
             self.sd.set('Credentials', 'aws_secret_access_key', ec2.aws_secret_access_key)
-        s = StringIO.StringIO()
+        s = io.StringIO()
         self.sd.write(s)
         rs = ec2.get_all_images([ami_id])
         img = rs[0]
@@ -119,15 +119,15 @@
                     max_count=self.options.num_instances,
                     instance_type=instance_type,
                     security_groups=[security_group])
-        print 'Starting AMI: %s' % ami_id
-        print 'Reservation %s contains the following instances:' % r.id
+        print('Starting AMI: %s' % ami_id)
+        print('Reservation %s contains the following instances:' % r.id)
         for i in r.instances:
-            print '\t%s' % i.id
+            print('\t%s' % i.id)
 
     def do_status(self):
         iq = self.sd.get_obj('input_queue')
         if iq:
-            print 'The input_queue (%s) contains approximately %s messages' % (iq.id, iq.count())
+            print('The input_queue (%s) contains approximately %s messages' % (iq.id, iq.count()))
         ob = self.sd.get_obj('output_bucket')
         ib = self.sd.get_obj('input_bucket')
         if ob:
@@ -136,7 +136,7 @@
             total = 0
             for k in ob:
                 total += 1
-            print 'The output_bucket (%s) contains %d keys' % (ob.name, total)
+            print('The output_bucket (%s) contains %d keys' % (ob.name, total))
 
     def do_retrieve(self):
         if not self.options.path:
@@ -151,10 +151,10 @@
     def do_batches(self):
         d = self.sd.get_obj('output_domain')
         if d:
-            print 'Available Batches:'
+            print('Available Batches:')
             rs = d.query("['type'='Batch']")
             for item in rs:
-                print '  %s' % item.name
+                print('  %s' % item.name)
         else:
             self.parser.error('No output_domain specified for service')
             
--- services/result.py	(original)
+++ services/result.py	(refactored)
@@ -84,7 +84,7 @@
                 key_name = output.split(';')[0]
                 key = bucket.lookup(key_name)
                 file_name = os.path.join(path, key_name)
-                print 'retrieving file: %s to %s' % (key_name, file_name)
+                print('retrieving file: %s to %s' % (key_name, file_name))
                 key.get_contents_to_filename(file_name)
             self.num_files += 1
 
@@ -105,10 +105,10 @@
     def get_results_from_bucket(self, path):
         bucket = self.sd.get_obj('output_bucket')
         if bucket:
-            print 'No output queue or domain, just retrieving files from output_bucket'
+            print('No output queue or domain, just retrieving files from output_bucket')
             for key in bucket:
                 file_name = os.path.join(path, key)
-                print 'retrieving file: %s to %s' % (key, file_name)
+                print('retrieving file: %s to %s' % (key, file_name))
                 key.get_contents_to_filename(file_name)
                 self.num_files + 1
 
@@ -123,14 +123,14 @@
             self.get_results_from_bucket(path)
         if self.log_fp:
             self.log_fp.close()
-        print '%d results successfully retrieved.' % self.num_files
+        print('%d results successfully retrieved.' % self.num_files)
         if self.num_files > 0:
             self.avg_time = float(self.total_time)/self.num_files
-            print 'Minimum Processing Time: %d' % self.min_time.seconds
-            print 'Maximum Processing Time: %d' % self.max_time.seconds
-            print 'Average Processing Time: %f' % self.avg_time
+            print('Minimum Processing Time: %d' % self.min_time.seconds)
+            print('Maximum Processing Time: %d' % self.max_time.seconds)
+            print('Average Processing Time: %f' % self.avg_time)
             self.elapsed_time = self.latest_time-self.earliest_time
-            print 'Elapsed Time: %d' % self.elapsed_time.seconds
+            print('Elapsed Time: %d' % self.elapsed_time.seconds)
             tput = 1.0 / ((self.elapsed_time.seconds/60.0) / self.num_files)
-            print 'Throughput: %f transactions / minute' % tput
+            print('Throughput: %f transactions / minute' % tput)
 
--- services/submit.py	(original)
+++ services/submit.py	(refactored)
@@ -77,12 +77,12 @@
                 for file in files:
                     fullpath = os.path.join(root, file)
                     if status:
-                        print 'Submitting %s' % fullpath
+                        print('Submitting %s' % fullpath)
                     self.submit_file(fullpath, metadata, cb, num_cb, prefix)
                     total += 1
         elif os.path.isfile(path):
             self.submit_file(path, metadata, cb, num_cb)
             total += 1
         else:
-            print 'problem with %s' % path
+            print('problem with %s' % path)
         return (metadata['Batch'], total)
--- ses/__init__.py	(original)
+++ ses/__init__.py	(refactored)
@@ -20,7 +20,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-from connection import SESConnection
+from .connection import SESConnection
 from boto.regioninfo import RegionInfo, get_regions
 
 
--- ses/connection.py	(original)
+++ ses/connection.py	(refactored)
@@ -20,7 +20,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 import re
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import base64
 
 from boto.connection import AWSAuthConnection
@@ -71,7 +71,7 @@
         :type label: string
         :param label: The parameter list's name
         """
-        if isinstance(items, basestring):
+        if isinstance(items, str):
             items = [items]
         for i in range(1, len(items) + 1):
             params['%s.%d' % (label, i)] = items[i - 1]
@@ -91,15 +91,15 @@
         params = params or {}
         params['Action'] = action
 
-        for k, v in params.items():
-            if isinstance(v, unicode):  # UTF-8 encode only if it's Unicode
+        for k, v in list(params.items()):
+            if isinstance(v, str):  # UTF-8 encode only if it's Unicode
                 params[k] = v.encode('utf-8')
 
         response = super(SESConnection, self).make_request(
             'POST',
             '/',
             headers=headers,
-            data=urllib.urlencode(params)
+            data=urllib.parse.urlencode(params)
         )
         body = response.read()
         if response.status == 200:
@@ -306,7 +306,7 @@
 
         """
 
-        if isinstance(raw_message, unicode):
+        if isinstance(raw_message, str):
             raw_message = raw_message.encode('utf-8')
 
         params = {
--- sns/__init__.py	(original)
+++ sns/__init__.py	(refactored)
@@ -22,7 +22,7 @@
 
 # this is here for backward compatibility
 # originally, the SNSConnection class was defined here
-from connection import SNSConnection
+from .connection import SNSConnection
 from boto.regioninfo import RegionInfo, get_regions
 
 
--- sns/connection.py	(original)
+++ sns/connection.py	(refactored)
@@ -95,8 +95,8 @@
       :param dictionary: dict - value of the serialized parameter
       :param name: name of the serialized parameter
       """
-      items = sorted(dictionary.items(), key=lambda x:x[0])
-      for kv, index in zip(items, range(1, len(items)+1)):
+      items = sorted(list(dictionary.items()), key=lambda x:x[0])
+      for kv, index in zip(items, list(range(1, len(items)+1))):
         key, value = kv
         prefix = '%s.entry.%s' % (name, index)
         params['%s.key' % prefix] = key
--- sqs/__init__.py	(original)
+++ sqs/__init__.py	(refactored)
@@ -20,7 +20,7 @@
 # IN THE SOFTWARE.
 #
 
-from regioninfo import SQSRegionInfo
+from .regioninfo import SQSRegionInfo
 from boto.regioninfo import get_regions
 
 
--- sqs/connection.py	(original)
+++ sqs/connection.py	(refactored)
@@ -288,7 +288,7 @@
             params['DelaySeconds'] = int(delay_seconds)
 
         if message_attributes is not None:
-            for i, name in enumerate(message_attributes.keys(), start=1):
+            for i, name in enumerate(list(message_attributes.keys()), start=1):
                 attribute = message_attributes[name]
                 params['MessageAttribute.%s.Name' % i] = name
                 if 'data_type' in attribute:
--- sqs/message.py	(original)
+++ sqs/message.py	(refactored)
@@ -64,7 +64,7 @@
 """
 
 import base64
-import StringIO
+import io
 from boto.sqs.attributes import Attributes
 from boto.sqs.messageattributes import MessageAttributes
 from boto.exception import SQSDecodeError
@@ -191,7 +191,7 @@
     def decode(self, value):
         try:
             msg = {}
-            fp = StringIO.StringIO(value)
+            fp = io.StringIO(value)
             line = fp.readline()
             while line:
                 delim = line.find(':')
@@ -205,7 +205,7 @@
 
     def encode(self, value):
         s = ''
-        for item in value.items():
+        for item in list(value.items()):
             s = s + '%s: %s\n' % (item[0], item[1])
         return s
 
@@ -223,13 +223,13 @@
         self.set_body(self._body)
 
     def keys(self):
-        return self._body.keys()
+        return list(self._body.keys())
 
     def values(self):
-        return self._body.values()
+        return list(self._body.values())
 
     def items(self):
-        return self._body.items()
+        return list(self._body.items())
 
     def has_key(self, key):
         return key in self._body
--- sqs/queue.py	(original)
+++ sqs/queue.py	(refactored)
@@ -23,7 +23,7 @@
 Represents an SQS Queue
 """
 
-import urlparse
+import urllib.parse
 from boto.sqs.message import Message
 
 
@@ -40,7 +40,7 @@
 
     def _id(self):
         if self.url:
-            val = urlparse.urlparse(self.url)[2]
+            val = urllib.parse.urlparse(self.url)[2]
         else:
             val = self.url
         return val
@@ -48,7 +48,7 @@
 
     def _name(self):
         if self.url:
-            val = urlparse.urlparse(self.url)[2].split('/')[2]
+            val = urllib.parse.urlparse(self.url)[2].split('/')[2]
         else:
             val = self.url
         return  val
@@ -475,7 +475,7 @@
                 m = Message(self, body)
                 self.write(m)
                 n += 1
-                print 'writing message %d' % n
+                print('writing message %d' % n)
                 body = ''
             else:
                 body = body + l
--- sts/__init__.py	(original)
+++ sts/__init__.py	(refactored)
@@ -20,7 +20,7 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 # IN THE SOFTWARE.
 
-from connection import STSConnection
+from .connection import STSConnection
 from boto.regioninfo import RegionInfo, get_regions
 
 
--- sts/connection.py	(original)
+++ sts/connection.py	(refactored)
@@ -23,8 +23,8 @@
 
 from boto.connection import AWSQueryConnection
 from boto.regioninfo import RegionInfo
-from credentials import Credentials, FederationToken, AssumedRole
-from credentials import DecodeAuthorizationMessage
+from .credentials import Credentials, FederationToken, AssumedRole
+from .credentials import DecodeAuthorizationMessage
 import boto
 import boto.utils
 import datetime
--- sts/credentials.py	(original)
+++ sts/credentials.py	(refactored)
@@ -116,7 +116,7 @@
         fp = open(file_path, 'wb')
         json.dump(self.to_dict(), fp)
         fp.close()
-        os.chmod(file_path, 0600)
+        os.chmod(file_path, 0o600)
 
     def is_expired(self, time_offset_seconds=0):
         """
--- swf/layer1.py	(original)
+++ swf/layer1.py	(refactored)
@@ -96,7 +96,7 @@
         :type data: dict
         :param data: Specifies request parameters with default values to be removed.
         """
-        for item in data.keys():
+        for item in list(data.keys()):
             if isinstance(data[item], dict):
                 cls._normalize_request_dict(data[item])
             if data[item] in (None, {}):
--- utils.py	(original)
+++ utils.py	(refactored)
@@ -40,11 +40,11 @@
 """
 
 import socket
-import urllib
-import urllib2
+import urllib.request, urllib.parse, urllib.error
+import urllib.request, urllib.error, urllib.parse
 import imp
 import subprocess
-import StringIO
+import io
 import time
 import logging.handlers
 import boto
@@ -111,7 +111,7 @@
     if len(nv) == 1:
         return nv
     else:
-        return (nv[0], urllib.unquote(nv[1]))
+        return (nv[0], urllib.parse.unquote(nv[1]))
 
 
 def canonical_string(method, path, headers, expires=None,
@@ -177,7 +177,7 @@
         provider = boto.provider.get_default()
     metadata_prefix = provider.metadata_prefix
     final_headers = headers.copy()
-    for k in metadata.keys():
+    for k in list(metadata.keys()):
         if k.lower() in ['cache-control', 'content-md5', 'content-type',
                          'content-encoding', 'content-disposition',
                          'expires']:
@@ -193,11 +193,11 @@
         provider = boto.provider.get_default()
     metadata_prefix = provider.metadata_prefix
     metadata = {}
-    for hkey in headers.keys():
+    for hkey in list(headers.keys()):
         if hkey.lower().startswith(metadata_prefix):
-            val = urllib.unquote(headers[hkey])
+            val = urllib.parse.unquote(headers[hkey])
             try:
-                metadata[hkey[len(metadata_prefix):]] = unicode(val, 'utf-8')
+                metadata[hkey[len(metadata_prefix):]] = str(val, 'utf-8')
             except UnicodeDecodeError:
                 metadata[hkey[len(metadata_prefix):]] = val
             del headers[hkey]
@@ -213,13 +213,13 @@
     """
     for i in range(0, num_retries):
         try:
-            proxy_handler = urllib2.ProxyHandler({})
-            opener = urllib2.build_opener(proxy_handler)
-            req = urllib2.Request(url)
+            proxy_handler = urllib.request.ProxyHandler({})
+            opener = urllib.request.build_opener(proxy_handler)
+            req = urllib.request.Request(url)
             r = opener.open(req)
             result = r.read()
             return result
-        except urllib2.HTTPError, e:
+        except urllib.error.HTTPError as e:
             # in 2.6 you use getcode(), in 2.5 and earlier you use code
             if hasattr(e, 'getcode'):
                 code = e.getcode()
@@ -227,7 +227,7 @@
                 code = e.code
             if code == 404 and not retry_on_404:
                 return ''
-        except Exception, e:
+        except Exception as e:
             pass
         boto.log.exception('Caught exception reading instance data')
         # If not on the last iteration of the loop then sleep.
@@ -284,7 +284,7 @@
             for i in range(0, self._num_retries):
                 try:
                     val = boto.utils.retry_url(
-                        self._url + urllib.quote(resource,
+                        self._url + urllib.parse.quote(resource,
                                                  safe="/:"),
                         num_retries=self._num_retries)
                     if val and val[0] == '{':
@@ -296,14 +296,14 @@
                             val = val.split('\n')
                         break
 
-                except JSONDecodeError, e:
+                except JSONDecodeError as e:
                     boto.log.debug(
                         "encountered '%s' exception: %s" % (
                             e.__class__.__name__, e))
                     boto.log.debug(
                         'corrupted JSON data found: %s' % val)
 
-                except Exception, e:
+                except Exception as e:
                     boto.log.debug("encountered unretryable" +
                                    " '%s' exception, re-raising" % (
                                        e.__class__.__name__))
@@ -337,11 +337,11 @@
 
     def values(self):
         self._materialize()
-        return super(LazyLoadMetadata, self).values()
+        return list(super(LazyLoadMetadata, self).values())
 
     def items(self):
         self._materialize()
-        return super(LazyLoadMetadata, self).items()
+        return list(super(LazyLoadMetadata, self).items())
 
     def __str__(self):
         self._materialize()
@@ -395,7 +395,7 @@
     try:
         metadata_url = _build_instance_metadata_url(url, version, data)
         return _get_instance_metadata(metadata_url, num_retries=num_retries)
-    except urllib2.URLError, e:
+    except urllib.error.URLError as e:
         return None
     finally:
         if timeout is not None:
@@ -423,7 +423,7 @@
             if field:
                 iid[field] = val
         return iid
-    except urllib2.URLError, e:
+    except urllib.error.URLError as e:
         return None
     finally:
         if timeout is not None:
@@ -491,7 +491,7 @@
     """
     dme_url = 'https://www.dnsmadeeasy.com/servlet/updateip'
     dme_url += '?username=%s&password=%s&id=%s&ip=%s'
-    s = urllib2.urlopen(dme_url % (username, password, dme_id, ip_address))
+    s = urllib.request.urlopen(dme_url % (username, password, dme_id, ip_address))
     return s.read()
 
 
@@ -515,12 +515,12 @@
             key.get_contents_to_file(file)
         else:
             if username and password:
-                passman = urllib2.HTTPPasswordMgrWithDefaultRealm()
+                passman = urllib.request.HTTPPasswordMgrWithDefaultRealm()
                 passman.add_password(None, uri, username, password)
-                authhandler = urllib2.HTTPBasicAuthHandler(passman)
-                opener = urllib2.build_opener(authhandler)
-                urllib2.install_opener(opener)
-            s = urllib2.urlopen(uri)
+                authhandler = urllib.request.HTTPBasicAuthHandler(passman)
+                opener = urllib.request.build_opener(authhandler)
+                urllib.request.install_opener(opener)
+            s = urllib.request.urlopen(uri)
             file.write(s.read())
         file.seek(0)
     except:
@@ -535,7 +535,7 @@
     def __init__(self, command, wait=True, fail_fast=False, cwd=None):
         self.exit_code = 0
         self.command = command
-        self.log_fp = StringIO.StringIO()
+        self.log_fp = io.StringIO()
         self.wait = wait
         self.fail_fast = fail_fast
         self.run(cwd=cwd)
@@ -673,7 +673,7 @@
 
     class _Item(object):
         def __init__(self, key, value):
-            self.previous = self.next = None
+            self.previous = self.__next__ = None
             self.key = key
             self.value = value
 
@@ -693,7 +693,7 @@
         cur = self.head
         while cur:
             yield cur.key
-            cur = cur.next
+            cur = cur.__next__
 
     def __len__(self):
         return len(self._dict)
@@ -741,8 +741,8 @@
             return
 
         previous = item.previous
-        previous.next = item.next
-        if item.next is not None:
+        previous.next = item.__next__
+        if item.__next__ is not None:
             item.next.previous = previous
         else:
             self.tail = previous
@@ -843,9 +843,9 @@
 
 
 def get_utf8_value(value):
-    if not isinstance(value, basestring):
+    if not isinstance(value, str):
         value = str(value)
-    if isinstance(value, unicode):
+    if isinstance(value, str):
         return value.encode('utf-8')
     else:
         return value
@@ -912,7 +912,7 @@
     rcontent = wrapper.as_string()
 
     if compress:
-        buf = StringIO.StringIO()
+        buf = io.StringIO()
         gz = gzip.GzipFile(mode='wb', fileobj=buf)
         try:
             gz.write(rcontent)
@@ -944,7 +944,7 @@
         '#cloud-boothook': 'text/cloud-boothook'
     }
     rtype = deftype
-    for possible_type, mimetype in starts_with_mappings.items():
+    for possible_type, mimetype in list(starts_with_mappings.items()):
         if content.startswith(possible_type):
             rtype = mimetype
             break
